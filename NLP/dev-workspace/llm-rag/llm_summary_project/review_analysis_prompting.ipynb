{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4 of the LLM per game TLDR generation project\n",
    "\n",
    "some of the game contains the topic stuff, some of the game does not\n",
    "\n",
    "assume we target with games with custom topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys, pickle, json, traceback\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_steamid = 1716740              # starfield\n",
    "game_name = 'starfield'             # also the folder name where the reviews are stored\n",
    "\n",
    "# game_steamid = 1118010\n",
    "# game_name = 'monster_hunter_world_iceborne'\n",
    "\n",
    "# game_steamid = 582010\n",
    "# game_name = 'monster_hunter_world'\n",
    "\n",
    "# game_steamid = 2138330          # cyberpunk2077 phantom liberty\n",
    "# game_name = 'cyberpunk2077_phantom_liberty'\n",
    "\n",
    "# game_steamid = 1091500          # cyberpunk2077\n",
    "# game_name = 'cyberpunk2077'\n",
    "\n",
    "# game_steamid = 730\n",
    "# game_name = 'counter-strike_2'\n",
    "\n",
    "# game_steamid = 570\n",
    "# game_name = \"dota2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../../dataset/data_scraping/steam_comments_scraping/starfield/steam_reviews_1716740_unique_with_gendata_with_analysis.pkl\n",
      "\n",
      "Loaded ageReviews_df\n",
      "Loaded genderReviews_df\n",
      "Loaded sentimentReviews_df\n",
      "Loaded sentimentReviews_truelabel_df\n",
      "Loaded sentimentByAgeGroup_df\n",
      "Loaded sentimentByGender_df\n"
     ]
    }
   ],
   "source": [
    "# load the reviews from folder\n",
    "\n",
    "reviews_reqs = []\n",
    "\n",
    "# get existing folder and retrieve the cursor object (?)\n",
    "\n",
    "# load the latest file\n",
    "game_folder = Path(f'../../dataset/data_scraping/steam_comments_scraping/{game_name}')\n",
    "if game_folder.exists():\n",
    "    try:\n",
    "        latest_file_path = game_folder.joinpath(f'steam_reviews_{game_steamid}_unique_with_gendata_with_analysis.pkl')\n",
    "        with open(latest_file_path, 'rb') as f:\n",
    "            reviews_reqs = pickle.load(f)           # retrieve the list of reviews\n",
    "            print('Loaded:', latest_file_path)\n",
    "    except IndexError as e:\n",
    "        print('Error loading the latest file:', e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "print()\n",
    "\n",
    "# also load different generated data\n",
    "ageReviews_df = pd.read_csv(game_folder.joinpath(f'steam_reviews_{game_steamid}_unique_with_gendata_with_analysis_ageGroup.csv'), index_col=None)\n",
    "print('Loaded ageReviews_df')\n",
    "genderReviews_df = pd.read_csv(game_folder.joinpath(f'steam_reviews_{game_steamid}_unique_with_gendata_with_analysis_genderReviews.csv'), index_col=None)\n",
    "print('Loaded genderReviews_df')\n",
    "sentimentReviews_df = pd.read_csv(game_folder.joinpath(f'steam_reviews_{game_steamid}_unique_with_gendata_with_analysis_sentimentReviews.csv'), index_col=None)\n",
    "print('Loaded sentimentReviews_df')\n",
    "sentimentReviews_truelabel_df = pd.read_csv(game_folder.joinpath(f'steam_reviews_{game_steamid}_unique_with_gendata_with_analysis_sentimentReviews_truelabel.csv'), index_col=None)\n",
    "print('Loaded sentimentReviews_truelabel_df')\n",
    "sentimentByAgeGroup_df = pd.read_csv(game_folder.joinpath(f'steam_reviews_{game_steamid}_unique_with_gendata_with_analysis_sentimentByAgeGroup.csv'), index_col=None)\n",
    "print('Loaded sentimentByAgeGroup_df')\n",
    "sentimentByGender_df = pd.read_csv(game_folder.joinpath(f'steam_reviews_{game_steamid}_unique_with_gendata_with_analysis_sentimentByGender.csv'), index_col=None)\n",
    "print('Loaded sentimentByGender_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13-19</td>\n",
       "      <td>9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-29</td>\n",
       "      <td>38403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30-39</td>\n",
       "      <td>29110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40-49</td>\n",
       "      <td>14313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50-59</td>\n",
       "      <td>4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60-69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70-79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80-89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90-99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_group  count\n",
       "0     13-19   9833\n",
       "1     20-29  38403\n",
       "2     30-39  29110\n",
       "3     40-49  14313\n",
       "4     50-59   4800\n",
       "5     60-69      0\n",
       "6     70-79      0\n",
       "7     80-89      0\n",
       "8     90-99      0\n",
       "9       NaN      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageReviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "# from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt constants\n",
    "\n",
    "SYSTEM_PROMPT_TEMPLATE = \\\n",
    "'''You have access to a pandas dataframe `df`. {description_of_the_table}\n",
    "Here is the output of `df.to_markdown()`:\n",
    "```\n",
    "{df_markdown}\n",
    "```\n",
    "'''\n",
    "\n",
    "# TODO: can further optimize?? Currently this is copied from IELTS academic writing task 1\n",
    "PROMPT_TEMPLATE = \\\n",
    "'''Summarise the information by selecting and reporting the main features, and main comparisons where relevant. Output a paragraph with less than 50 words.\n",
    "Only output the paragraph. Do NOT output other text.'''\n",
    "\n",
    "\n",
    "DESCRIPTION_AGEREVIEW_DF = \\\n",
    "'''df is a dataframe that describes the distribution of reviews by age group.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_mistral7b = Ollama(\n",
    "    model='mistral:7b-instruct-v0.2-q4_0', temperature=0.4,\n",
    "    num_gpu = 1,        # disable/enable gpu for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks for detecting token usage (Ollama only)\n",
    "# copoed from llm_rag_comparison.ipynb\n",
    "\n",
    "from langchain_core.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.outputs.llm_result import LLMResult\n",
    "from collections import deque\n",
    "\n",
    "class TokenUsageCallbackHandler(BaseCallbackHandler):\n",
    "\n",
    "    def __init__(self, deque: deque = None):\n",
    "        super().__init__()\n",
    "        self.deque = deque\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "        # print(response)\n",
    "\n",
    "        generation = response.generations[0][0]\n",
    "        gen_info = generation.generation_info\n",
    "\n",
    "        # get token usage\n",
    "        # ref: https://github.com/orgs/langfuse/discussions/1179\n",
    "        token_usage = gen_info.get('prompt_eval_count', 0) + gen_info.get('eval_count', 0)\n",
    "        # get time costed (local machine)\n",
    "        # instead of getting total duration, we get the prompt_eval_duration and eval_duration to exclude the load duration (e.g. to load the model to the gpu, etc.)\n",
    "        time_costed = gen_info.get('prompt_eval_duration', 1e-10) + gen_info.get('eval_duration', 1e-10)     # in ns, a small value to indicate a inf time when it fails\n",
    "\n",
    "\n",
    "        # create an object to store the token usage and time costed\n",
    "        token_usage_obj = {\n",
    "            'token_usage': token_usage,\n",
    "            'time_costed': time_costed\n",
    "        }\n",
    "\n",
    "        # append the object to the deque\n",
    "        self.deque.append(token_usage_obj)\n",
    "\n",
    "\n",
    "def combine_token_usage_obj(token_usage_obj_list:list[dict]) -> dict:\n",
    "    token_usage = 0\n",
    "    time_costed = 0\n",
    "    for obj in token_usage_obj_list:\n",
    "        token_usage += obj['token_usage']\n",
    "        time_costed += obj['time_costed']\n",
    "\n",
    "    return {\n",
    "        'token_usage': token_usage,\n",
    "        'time_costed': time_costed\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "common_deque = deque()\n",
    "chain_config = {\n",
    "    \"callbacks\": [TokenUsageCallbackHandler(common_deque)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The dataframe `df` presents age group distributions of reviews, with the largest number of reviews falling in the 20-29 age group (38,403). The youngest age group, 13-19, has 9,833 reviews, while other age groups, from 30-59, have substantial numbers as well. No reviews were recorded for ages 60 and above.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "chat_prompt_01 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_PROMPT_TEMPLATE),\n",
    "    (\"user\", PROMPT_TEMPLATE),\n",
    "])\n",
    "\n",
    "chain_01 = chat_prompt_01 | llm_mistral7b\n",
    "\n",
    "resp_01 = chain_01.invoke({\n",
    "    'df_markdown': ageReviews_df.to_markdown(),\n",
    "    'description_of_the_table': DESCRIPTION_AGEREVIEW_DF,\n",
    "}, config=chain_config)\n",
    "\n",
    "token_usage_01 = common_deque.popleft()\n",
    "\n",
    "print(resp_01)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-test-wsl-tm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
