{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 480\n",
    "DATASET_IS_BALANCED = True\n",
    "\n",
    "\n",
    "MAX_FEATURES = 20000        # max_features params for CountVectorizer\n",
    "\n",
    "training_args_datetime = datetime(year=2024, month=2, day=26)\n",
    "training_name = 'glove-cnn-{}_{}k_{}_{}'.format(\n",
    "    MAX_FEATURES,\n",
    "    DATASET_SIZE,\n",
    "    'bal' if DATASET_IS_BALANCED else 'imbal',\n",
    "    training_args_datetime.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "training_storing_folder = Path(training_name).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 11:20:31.851189: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:31.914759: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:31.914798: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:31.916219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:31.916247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:31.916262: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:32.106876: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:32.106925: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:32.106932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-15 11:20:32.106955: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:32.106971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21472 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Loaded text vectorizer from /root/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_480k_bal_2024-02-26/glove-cnn-20000_480k_bal_2024-02-26_textvectorizer.pkl\n",
      "Loaded model from /root/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_480k_bal_2024-02-26/glove-cnn-20000_480k_bal_2024-02-26_model.keras\n",
      "Loaded end to end model from /root/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_480k_bal_2024-02-26/glove-cnn-20000_480k_bal_2024-02-26_end2end.keras\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# load the tf model\n",
    "# either a end-to-end\n",
    "# or build our own (by loading the vectorizer and the model)\n",
    "\n",
    "\n",
    "text_vectorizer_path = Path.joinpath(training_storing_folder, \"{}_textvectorizer.pkl\".format(\n",
    "    training_name,\n",
    "    # training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "))\n",
    "vectorizer_from_disk = pickle.load(open(text_vectorizer_path, 'rb'))\n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_sequence_length=512)\n",
    "\n",
    "vectorizer.set_weights(vectorizer_from_disk['weights'])\n",
    "\n",
    "model_path = Path.joinpath(training_storing_folder, \"{}_model.keras\".format(\n",
    "    training_name,\n",
    "    # training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "))\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "end_to_end_model_path = Path.joinpath(training_storing_folder, \"{}_end2end.keras\".format(\n",
    "    training_name,\n",
    "    # training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "))\n",
    "\n",
    "end_to_end_model = keras.models.load_model(end_to_end_model_path)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Loaded text vectorizer from {}'.format(text_vectorizer_path))\n",
    "print('Loaded model from {}'.format(model_path))\n",
    "print('Loaded end to end model from {}'.format(end_to_end_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 512)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " model (Functional)          (None, 2)                 6808154   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6808154 (25.97 MB)\n",
      "Trainable params: 6808154 (25.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "end_to_end_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'and',\n",
       " 'to',\n",
       " 'a',\n",
       " 'game',\n",
       " 'i',\n",
       " 'it',\n",
       " 'of',\n",
       " 'you',\n",
       " 'is',\n",
       " 'this',\n",
       " 'in',\n",
       " 'that',\n",
       " 'for',\n",
       " 'but',\n",
       " 's',\n",
       " 'with',\n",
       " 't']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 512, 300)             6000600   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 506, 128)             268928    ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 506, 128)             268928    ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 506, 128)             268928    ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 1, 128)               0         ['conv1d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1, 128)               0         ['conv1d_1[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 1, 128)               0         ['conv1d_2[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 1, 384)               0         ['max_pooling1d[0][0]',       \n",
      "                                                                     'max_pooling1d_1[0][0]',     \n",
      "                                                                     'max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 384)                  0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 384)                  0         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 2)                    770       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6808154 (25.97 MB)\n",
      "Trainable params: 6808154 (25.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the .keras model to SavedModel format\n",
    "# which include a .pb file\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format\n",
    "\n",
    "# model.save(Path.joinpath(training_storing_folder, \"{}_{}_model_savedmodel\".format(\n",
    "#     training_name,\n",
    "#     training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "# )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not search for non-variable resources. Concrete function internal representation may have changed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_480k_bal_2024-02-26\n",
      "\n",
      "\n",
      "\n",
      "/root/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_480k_bal_2024-02-26/glove-cnn-20000_480k_bal_2024-02-26_2024-02-26_modelonly.onnx\n",
      "WARNING:tensorflow:Issue encountered when serializing table_initializer.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 11:20:51.212133: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.212182: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-03-15 11:20:51.212250: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-03-15 11:20:51.212450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.212468: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.212478: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.212590: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.212595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-15 11:20:51.212608: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.212616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21472 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-03-15 11:20:51.455287: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.455352: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.455364: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.455533: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.455547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-15 11:20:51.455568: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.455579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21472 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-03-15 11:20:51.498032: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.498081: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-03-15 11:20:51.498172: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-03-15 11:20:51.498378: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.498406: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.498417: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.498561: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.498568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-15 11:20:51.498584: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-15 11:20:51.498593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21472 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# save the pretrained model to onnx\n",
    "\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "onnx_model_path = Path.joinpath(training_storing_folder, \"{}_modelonly.onnx\".format(\n",
    "    training_name,\n",
    "    # training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "))\n",
    "\n",
    "print(training_storing_folder)\n",
    "print('\\n\\n')\n",
    "print(onnx_model_path)\n",
    "\n",
    "# Keras models and tf functions and can be converted directly within python\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=[tf.TensorSpec([None,512], dtype=tf.int32, name='input')],     # match the input name of the model\n",
    "    # extra_opset=['ai.onnx.contrib:1'],\n",
    "    opset=15        # default opset of tf2onnx for testing\n",
    ")\n",
    "\n",
    "onnx.save(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/onnx/tensorflow-onnx/issues/1867\n",
    "# \"probably there's no shared-name keyword for hash tables in TextVectorization layer.\"\n",
    "# Therefore we only convert the model without the vectorizer (resulting in like huggingface, that the tokenizer is not included in onnx)\n",
    "\n",
    "# !python -m tf2onnx.convert --saved-model \"glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-22_model_savedmodel\" --output \"glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-22_modelonly.onnx\" --extra_opset ai.onnx.contrib:1 --opset 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(\n",
    "    onnx_model_path,\n",
    "    providers=['CPUExecutionProvider']\n",
    ")\n",
    "\n",
    "input_name = [inp.name for inp in sess.get_inputs()][0]     # only one input in this model\n",
    "label_names = [label.name for label in sess.get_outputs()]  # it outputs the label and the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [['I like the game'], [\"I do not like it.\"], [\"It crashes when I just run on my pc.\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 11:21:01.001638: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 913ms/step\n",
      "WARNING:tensorflow:From /tmp/ipykernel_17997/1925086723.py:12: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity with explicit device placement instead.\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[array([[0.24413665, 0.75586337]], dtype=float32), array([[0.8491382 , 0.15086186]], dtype=float32), array([[0.8683612 , 0.13163884]], dtype=float32)]\n",
      "[[array([[0.24412242, 0.7558776 ]], dtype=float32)], [array([[0.84912586, 0.15087417]], dtype=float32)], [array([[0.8683908 , 0.13160917]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "pred_keras = []\n",
    "perd_onnx = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    # keras inference\n",
    "    pred_keras.append(end_to_end_model.predict(test_data[i]))\n",
    "\n",
    "    # onnx inference\n",
    "    v_out = vectorizer(test_data[i])\n",
    "    perd_onnx.append(sess.run(None, {\"input\": v_out.cpu().numpy().astype(np.int32)}))\n",
    "\n",
    "print(pred_keras)\n",
    "print(perd_onnx)\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    result_keras = pred_keras[i]\n",
    "    result_onnx = perd_onnx[i][0]\n",
    "\n",
    "    np.testing.assert_allclose(result_keras, result_onnx, rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
