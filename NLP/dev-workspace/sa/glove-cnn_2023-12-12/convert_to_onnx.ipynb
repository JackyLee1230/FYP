{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 120\n",
    "DATASET_IS_BALANCED = True\n",
    "\n",
    "\n",
    "MAX_FEATURES = 20000        # max_features params for CountVectorizer\n",
    "\n",
    "training_name = 'glove-cnn-{}_{}k_{}'.format(\n",
    "    MAX_FEATURES,\n",
    "    DATASET_SIZE,\n",
    "    'bal' if DATASET_IS_BALANCED else 'imbal'\n",
    ")\n",
    "\n",
    "training_args_datetime = datetime(year=2023, month=12, day=20)\n",
    "training_storing_folder = Path(training_name).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End to end model not found at /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end.keras\n",
      "Attempt to build from existing vectorizer and model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 10:08:13.808253: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2023-12-22 10:08:13.808275: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-12-22 10:08:13.808280: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-12-22 10:08:13.808322: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-22 10:08:13.808338: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Loaded text vectorizer from /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_textvectorizer.pkl\n",
      "Loaded model from /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_model.keras\n",
      "Created end to end model from trained vectorizer and cnn-model\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# load the tf model\n",
    "# either a end-to-end\n",
    "# or build our own (by loading the vectorizer and the model)\n",
    "\n",
    "\n",
    "text_vectorizer_path = Path.joinpath(training_storing_folder, \"{}_{}_textvectorizer.pkl\".format(\n",
    "    training_name,\n",
    "    training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "))\n",
    "vectorizer_from_disk = pickle.load(open(text_vectorizer_path, 'rb'))\n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_sequence_length=512)\n",
    "\n",
    "vectorizer.set_weights(vectorizer_from_disk['weights'])\n",
    "\n",
    "model_path = Path.joinpath(training_storing_folder, \"{}_{}_model.keras\".format(\n",
    "    training_name,\n",
    "    training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "))\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Loaded text vectorizer from {}'.format(text_vectorizer_path))\n",
    "print('Loaded model from {}'.format(model_path))\n",
    "\n",
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "print('Created end to end model from trained vectorizer and cnn-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 512)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " model_4 (Functional)        (None, 2)                 6808154   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6808154 (25.97 MB)\n",
      "Trainable params: 6808154 (25.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "end_to_end_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end_savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end_savedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "# save the .keras model to SavedModel format\n",
    "# which include a .pb file\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format\n",
    "\n",
    "end_to_end_model.save(Path.joinpath(training_storing_folder, \"{}_{}_end2end_savedmodel\".format(\n",
    "    training_name,\n",
    "    training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pretrained model to onnx\n",
    "\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "onnx_model_path = Path.joinpath(training_storing_folder, \"{}_{}_end2end.onnx\".format(\n",
    "    training_name,\n",
    "    training_args_datetime.strftime(\"%Y-%m-%d\")\n",
    "))\n",
    "\n",
    "# onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "#     end_to_end_model,\n",
    "#     input_signature=[tf.TensorSpec([None,1], dtype=tf.string, name='input_3')],\n",
    "#     extra_opset='ai.onnx.contrib:1',\n",
    "#     opset=13        # support onnxruntime >= 1.13.0\n",
    "# )\n",
    "\n",
    "# onnx.save(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal\n",
      "\n",
      "\n",
      "\n",
      "/Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end.onnx\n"
     ]
    }
   ],
   "source": [
    "print(training_storing_folder)\n",
    "print('\\n\\n')\n",
    "print(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2023-12-22 10:19:03,389 - WARNING - tensorflow_text not installed. Model will fail to load if tensorflow_text ops are used.\n",
      "2023-12-22 10:19:03,391 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2023-12-22 10:19:03,570 - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "2023-12-22 10:19:03,704 - INFO - Signatures found in model: [serving_default].\n",
      "2023-12-22 10:19:03,704 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2023-12-22 10:19:03,704 - INFO - Output names: ['model_4']\n",
      "2023-12-22 10:19:03,704 - WARNING - Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-12-22 10:19:04,043 - INFO - Using tensorflow=2.15.0, onnx=1.14.1, tf2onnx=1.15.1/37820d\n",
      "2023-12-22 10:19:04,043 - INFO - Using opset <onnx, 15>\n",
      "2023-12-22 10:19:04,104 - WARNING - Cannot infer shape for StatefulPartitionedCall/model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2: StatefulPartitionedCall/model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2:0\n",
      "2023-12-22 10:19:04,104 - WARNING - Cannot infer shape for StatefulPartitionedCall/model/text_vectorization/string_lookup/SelectV2: StatefulPartitionedCall/model/text_vectorization/string_lookup/SelectV2:0\n",
      "2023-12-22 10:19:04,118 - INFO - Computed 0 values for constant folding\n",
      "{}\n",
      "2023-12-22 10:19:04,180 - ERROR - Failed to convert node 'StatefulPartitionedCall/model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2' (fct=<bound method LookupTableFind.version_8 of <class 'tf2onnx.custom_opsets.onnx_ml.LookupTableFind'>>)\n",
      "'OP=LookupTableFindV2\\nName=StatefulPartitionedCall/model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2\\nInputs:\\n\\tunknown:0=Placeholder, [], 7\\n\\tStatefulPartitionedCall/model/text_vectorization/StringSplit/StringSplitV2:1=StringSplit, [-1], 8\\n\\tFunc/StatefulPartitionedCall/input/_2:0=Const, [], 7\\nOutpus:\\n\\tStatefulPartitionedCall/model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2:0=[], 7'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/tfonnx.py\", line 292, in tensorflow_onnx_mapping\n",
      "    func(g, node, **kwargs, initialized_tables=initialized_tables, dequantize=dequantize)\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/custom_opsets/onnx_ml.py\", line 55, in version_8\n",
      "    cats_strings, cats_int64s = initialized_tables[shared_name]\n",
      "KeyError: 'LookupTableFindV2'\n",
      "2023-12-22 10:19:04,185 - WARNING - ONNX Failed to infer shapes and dtypes for [Compress__94, type: Compress]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/schemas.py\", line 154, in infer_onnx_shape_dtype\n",
      "    inferred_model = shape_inference.infer_shapes(model_proto, strict_mode=True)\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/onnx/shape_inference.py\", line 43, in infer_shapes\n",
      "    inferred_model_str = C.infer_shapes(\n",
      "onnx.onnx_cpp2py_export.shape_inference.InferenceError: [ShapeInferenceError] Shape inference error(s): (op_type:Compress, node name: Compress__94): [ShapeInferenceError] Indices tensor must have rank >= 1\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/convert.py\", line 714, in <module>\n",
      "    main()\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/convert.py\", line 273, in main\n",
      "    model_proto, _ = _convert_common(\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/convert.py\", line 168, in _convert_common\n",
      "    g = process_tf_graph(tf_graph, const_node_values=const_node_values,\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/tfonnx.py\", line 464, in process_tf_graph\n",
      "    g = process_graphs(main_g, subgraphs, custom_op_handlers, inputs_as_nchw, outputs_as_nchw, continue_on_error,\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/tfonnx.py\", line 516, in process_graphs\n",
      "    g = process_parsed_graph(main_g, custom_op_handlers, inputs_as_nchw, outputs_as_nchw, continue_on_error,\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/tfonnx.py\", line 627, in process_parsed_graph\n",
      "    raise exceptions[0]\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/tfonnx.py\", line 292, in tensorflow_onnx_mapping\n",
      "    func(g, node, **kwargs, initialized_tables=initialized_tables, dequantize=dequantize)\n",
      "  File \"/Users/michaelcheng/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/tf2onnx/custom_opsets/onnx_ml.py\", line 55, in version_8\n",
      "    cats_strings, cats_int64s = initialized_tables[shared_name]\n",
      "KeyError: 'LookupTableFindV2'\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/onnx/tensorflow-onnx/issues/1867\n",
    "# \"probably there's no shared-name keyword for hash tables\"\n",
    "\n",
    "!python -m tf2onnx.convert --saved-model \"/Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end_savedmodel\" --output \"/Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end.onnx\" --extra_opset ai.onnx.contrib:1 --opset 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end.onnx failed:Load model /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sess \u001b[38;5;241m=\u001b[39m \u001b[43mrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproviders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCPUExecutionProvider\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m input_name \u001b[38;5;241m=\u001b[39m [inp\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m sess\u001b[38;5;241m.\u001b[39mget_inputs()][\u001b[38;5;241m0\u001b[39m]     \u001b[38;5;66;03m# only one input in this model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m label_names \u001b[38;5;241m=\u001b[39m [label\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m sess\u001b[38;5;241m.\u001b[39mget_outputs()]  \u001b[38;5;66;03m# it outputs the label and the probability\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:419\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test2/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:452\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    450\u001b[0m session_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01melse\u001b[39;00m C\u001b[38;5;241m.\u001b[39mget_default_session_options()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_path:\n\u001b[0;32m--> 452\u001b[0m     sess \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_config_from_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     sess \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mInferenceSession(session_options, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_bytes, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_config_from_model)\n",
      "\u001b[0;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end.onnx failed:Load model /Users/michaelcheng/Documents/MyDocs/HKU/COMP4801 FYP/FYP/NLP/dev-workspace/sa/glove-cnn_2023-12-12/glove-cnn-20000_120k_bal/glove-cnn-20000_120k_bal_2023-12-20_end2end.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(\n",
    "    onnx_model_path,\n",
    "    providers=['CPUExecutionProvider']\n",
    ")\n",
    "\n",
    "input_name = [inp.name for inp in sess.get_inputs()][0]     # only one input in this model\n",
    "label_names = [label.name for label in sess.get_outputs()]  # it outputs the label and the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [['I like the game'], [\"I do not like it.\"], [\"It crashes when I just run on my pc.\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 23:27:40.454814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 371ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_data)):\n\u001b[1;32m      7\u001b[0m     pred_keras\u001b[38;5;241m.\u001b[39mappend(end_to_end_model\u001b[38;5;241m.\u001b[39mpredict(test_data[i]))\n\u001b[0;32m----> 8\u001b[0m     perd_onnx\u001b[38;5;241m.\u001b[39mappend(\u001b[43monnx_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(test_data[i]))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_keras)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(perd_onnx)\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "pred_keras = []\n",
    "perd_onnx = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred_keras.append(end_to_end_model.predict(test_data[i]))\n",
    "    perd_onnx.append(sess.run([\"output1\", \"output2\"], {\"input1\": test_data[i]}))\n",
    "\n",
    "print(pred_keras)\n",
    "print(perd_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
