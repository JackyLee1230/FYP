{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo ipynb for CTM (hyperparameters grid/random search)\n",
    "\n",
    "Combined TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "# from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"          # disable huggingface warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 75499 entries, 57735 to 133233\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   index         75499 non-null  int64 \n",
      " 1   app_id        75499 non-null  int64 \n",
      " 2   app_name      75499 non-null  object\n",
      " 3   review_text   75499 non-null  object\n",
      " 4   review_score  75499 non-null  int64 \n",
      " 5   review_votes  75499 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path('../../dataset/topic_modelling/top_10_games/00_Terraria.pkl')\n",
    "\n",
    "dataset = pd.read_pickle(dataset_path)\n",
    "\n",
    "dataset.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../sa/')\n",
    "\n",
    "%autoreload 2\n",
    "import str_cleaning_functions\n",
    "\n",
    "# copied from lda_demo_gridsearch.ipynb\n",
    "def cleaning(df, review):\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_links(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_links2(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.clean(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.deEmojify(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_non_letters(x))\n",
    "    df[review] = df[review].apply(lambda x: x.lower())\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.unify_whitespaces(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_stopword(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.unify_whitespaces(x))\n",
    "\n",
    "# def cleaning_strlist(str_list):\n",
    "#     str_list = list(map(lambda x: clean(x), str_list))\n",
    "#     str_list = list(map(lambda x: deEmojify(x), str_list))\n",
    "\n",
    "#     str_list = list(map(lambda x: x.lower(), str_list))\n",
    "#     str_list = list(map(lambda x: remove_num(x), str_list))\n",
    "#     str_list = list(map(lambda x: unify_whitespaces(x), str_list))\n",
    "\n",
    "#     str_list = list(map(lambda x: _deaccent(x), str_list))\n",
    "#     str_list = list(map(lambda x: remove_non_alphabets(x), str_list))\n",
    "#     str_list = list(map(lambda x: remove_stopword(x), str_list))\n",
    "#     return str_list\n",
    "\n",
    "# copied from bert_demo_gridsearch.ipynb\n",
    "def cleaning_little(df, review):\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_links(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_links2(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.clean(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.deEmojify(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.unify_whitespaces(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the dataset, as we need both untouched text and cleaned text\n",
    "\n",
    "dataset_preprocessed = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning(dataset_preprocessed, 'review_text')\n",
    "\n",
    "\n",
    "cleaning_little(dataset, 'review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = dataset_preprocessed['review_text'].values\n",
    "X = dataset['review_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply lemmatizing to the preprocessed dataset as well (for BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do lemmatization, but not stemming (as part of speech is important in topic modelling)\n",
    "# use nltk wordnet for lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# from https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word\n",
    "\n",
    "# from: https://www.cnblogs.com/jclian91/p/9898511.html\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None     # if none -> created as noun by wordnet\n",
    "    \n",
    "def lemmatization(text):\n",
    "   # use nltk to get PoS tag\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "\n",
    "    # then we only need adj, adv, verb, noun\n",
    "    # convert from nltk Penn Treebank tag to wordnet tag\n",
    "    wn_tagged = list(map(lambda x: (x[0], get_wordnet_pos(x[1])), tagged))\n",
    "\n",
    "    # lemmatize by the PoS\n",
    "    lemmatized = list(map(lambda x: lemma.lemmatize(x[0], pos=x[1] if x[1] else wordnet.NOUN), wn_tagged))\n",
    "    # lemma.lemmatize(wn_tagged[0], pos=wordnet.NOUN)\n",
    "\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = list(map(lambda x: lemmatization(x), X_preprocessed))\n",
    "X_preprocessed = list(map(lambda x: ' '.join(x), X_preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# copy from: https://github.com/MilaNLProc/contextualized-topic-models/blob/master/contextualized_topic_models/utils/data_preparation.py#L44\n",
    "# call bert_embeddings_from_list() to produce embeddings by ourself\n",
    "\n",
    "import warnings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "\n",
    "if platform.system() == 'Linux' or platform.system() == 'Windows':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    device = torch.device('mps')        # m-series mac machine\n",
    "\n",
    "print(device)\n",
    "\n",
    "def bert_embeddings_from_list(\n",
    "    texts, \n",
    "    model_name_or_path, \n",
    "    batch_size=32, \n",
    "    max_seq_length=None,            # 128 is the default valule in TopicModelDataPreparation() init. Passing none to use the default value of each model\n",
    "    device='cpu'):\n",
    "    \"\"\"\n",
    "    Creates SBERT Embeddings from a list\n",
    "    \"\"\"\n",
    "\n",
    "    model = SentenceTransformer(model_name_or_path, device=device)\n",
    "\n",
    "    if max_seq_length is not None:\n",
    "        model.max_seq_length = max_seq_length\n",
    "    else:\n",
    "        max_seq_length = model.max_seq_length\n",
    "\n",
    "    check_max_local_length(max_seq_length, texts)\n",
    "\n",
    "    return np.array(model.encode(texts, batch_size=batch_size, show_progress_bar=True))\n",
    "\n",
    "\n",
    "def check_max_local_length(max_seq_length, texts):\n",
    "    max_local_length = np.max([len(t.split()) for t in texts])\n",
    "    if max_local_length > max_seq_length:\n",
    "        warnings.simplefilter(\"always\", DeprecationWarning)\n",
    "        warnings.warn(\n",
    "            f\"the longest document in your collection has {max_local_length} words, the model instead \"\n",
    "            f\"truncates to {max_seq_length} tokens.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from eval_metrics import compute_inverted_rbo, compute_topic_diversity, compute_pairwise_jaccard_similarity, \\\n",
    "                        METRICS, SEARCH_BEHAVIOUR, COHERENCE_MODEL_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init params\n",
    "\n",
    "def _init_count_vectorizer_params(\n",
    "        max_features=2000,\n",
    "        ngram_range=(1,1)\n",
    "):\n",
    "    params_dict = {}\n",
    "    params_dict['max_features'] = max_features\n",
    "    params_dict['ngram_range'] = ngram_range\n",
    "\n",
    "    return params_dict\n",
    "\n",
    "def _init_sbert_params(\n",
    "    model_name_or_path='all-mpnet-base-v2'\n",
    "):\n",
    "    params_dict = {}\n",
    "    params_dict['model_name_or_path'] = model_name_or_path\n",
    "\n",
    "    return params_dict\n",
    "\n",
    "# params are copied from source code of CTM: https://github.com/MilaNLProc/contextualized-topic-models/blob/master/contextualized_topic_models/models/ctm.py#L131\n",
    "# commented params are params that has no plan on fine-tuning them (not significant to our project)\n",
    "def _init_ctm_params(\n",
    "        # bow_size,\n",
    "        # contextual_size,\n",
    "        # inference_type=\"combined\",\n",
    "        n_components=10,\n",
    "        # model_type=\"prodLDA\",\n",
    "        hidden_sizes=(100, 100),\n",
    "        # activation=\"softplus\",\n",
    "        dropout=0.2,\n",
    "        # learn_priors=True,\n",
    "        # batch_size=64,\n",
    "        lr=2e-3,\n",
    "        momentum=0.99,\n",
    "        solver=\"adam\",\n",
    "        num_epochs=100,\n",
    "        # reduce_on_plateau=False,      # only valid if there's a testing data (seems no need to havbe label, just partition a testing dataset with train_test_split()))\n",
    "        # num_data_loader_workers=mp.cpu_count(),\n",
    "        # label_size=0,\n",
    "        # loss_weights=None\n",
    "):\n",
    "    params_dict = {}\n",
    "    # params_dict['bow_size'] = bow_size                        # decided by the count vectorizer params (max_features)\n",
    "    # params_dict['contextual_size'] = contextual_size          # decided by the sbert model\n",
    "    # params_dict['inference_type'] = inference_type\n",
    "    params_dict['n_components'] = n_components\n",
    "    # params_dict['model_type'] = model_type\n",
    "    params_dict['hidden_sizes'] = hidden_sizes\n",
    "    # params_dict['activation'] = activation\n",
    "    params_dict['dropout'] = dropout\n",
    "    # params_dict['learn_priors'] = learn_priors\n",
    "    # params_dict['batch_size'] = batch_size\n",
    "    params_dict['lr'] = lr\n",
    "    params_dict['momentum'] = momentum\n",
    "    params_dict['solver'] = solver\n",
    "    params_dict['num_epochs'] = num_epochs\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_config_dict(config_path:Path, model_name:str, hyperparameters:dict, search_space_dict:dict, \n",
    "                      metrics:list[METRICS], monitor:METRICS,\n",
    "                      search_behaviour:SEARCH_BEHAVIOUR, search_rs:int, search_n_iter:int):\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        config = {}\n",
    "\n",
    "        sbert_params = _init_sbert_params(**hyperparameters['sbert_params'])\n",
    "        countvect_params = _init_count_vectorizer_params(**hyperparameters['countvect_params'])\n",
    "        ctm_params = _init_ctm_params(**hyperparameters['ctm_params'])\n",
    "\n",
    "        config['model'] = model_name\n",
    "        config['sbert_params'] = sbert_params\n",
    "        config['countvect_params'] = countvect_params\n",
    "        config['ctm_params'] = ctm_params\n",
    "\n",
    "        if 'sbert_params' in search_space_dict:\n",
    "            for k in search_space_dict['sbert_params'].keys():\n",
    "                sbert_params.pop(k, '')     # add a default value to avoid key error\n",
    "        if 'countvect_params' in search_space_dict:\n",
    "            for k in search_space_dict['countvect_params'].keys():\n",
    "                countvect_params.pop(k, '')\n",
    "        if 'ctm_params' in search_space_dict:\n",
    "            for k in search_space_dict['ctm_params'].keys():\n",
    "                ctm_params.pop(k, '')\n",
    "\n",
    "        config['search_space'] = search_space_dict\n",
    "        config['metrics'] = list(map(lambda x: x.value, metrics))\n",
    "        config['monitor'] = monitor.value\n",
    "\n",
    "        config['search_behaviour'] = search_behaviour.value\n",
    "        if search_behaviour == SEARCH_BEHAVIOUR.RANDOM_SEARCH:\n",
    "            config['search_rs'] = search_rs\n",
    "            config['search_n_iter'] = search_n_iter\n",
    "\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "\n",
    "        print('Created config file at {}'.format(config_path))\n",
    "    else:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        # check whether the input params are consistent with the config file\n",
    "        assert config['model'] == model_name, 'input model_name is not consistent with the config[\"model\"]'\n",
    "        assert config['metrics'] == list(map(lambda x: x.value, metrics)), 'input metrics is not consistent with config[\"metrics\"]'\n",
    "        assert config['monitor'] == monitor.value, 'input monitor is not consistent with config[\"monitor\"]'\n",
    "        assert config['search_behaviour'] == search_behaviour.value, 'input search_behaviour is not consistent with config[\"search_behaviour\"]'\n",
    "        if search_behaviour == SEARCH_BEHAVIOUR.RANDOM_SEARCH:\n",
    "            assert config['search_rs'] == search_rs, 'input search_rs is not consistent with config[\"search_rs\"]'\n",
    "            assert config['search_n_iter'] == search_n_iter, 'input search_n_iter is not consistent with config[\"search_n_iter\"]'\n",
    "\n",
    "        # check whether the hyperparameters are consistent with the config file\n",
    "        sbert_params = _init_sbert_params(**hyperparameters['sbert_params'])\n",
    "        countvect_params = _init_count_vectorizer_params(**hyperparameters['countvect_params'])\n",
    "        ctm_params = _init_ctm_params(**hyperparameters['ctm_params'])\n",
    "\n",
    "        assert config['sbert_params'].keys() <= sbert_params.keys(), 'existing config[\"sbert_params\"] contains additional hyperparameters'\n",
    "        assert config['countvect_params'].keys() <= countvect_params.keys(), 'existing config[\"countvect_params\"] contains additional hyperparameters'\n",
    "        assert config['ctm_params'].keys() <= ctm_params.keys(), 'existing config[\"ctm_params\"] contains additional hyperparameters'\n",
    "\n",
    "        for key in sbert_params.keys() & config['sbert_params'].keys():\n",
    "            assert sbert_params[key] == config['sbert_params'][key], 'existing config[\"sbert_params\"] contains different hyperparameters'\n",
    "        for key in countvect_params.keys() & config['countvect_params'].keys():\n",
    "            assert countvect_params[key] == config['countvect_params'][key], 'existing config[\"countvect_params\"] contains different hyperparameters'\n",
    "        for key in ctm_params.keys() & config['ctm_params'].keys():\n",
    "            assert ctm_params[key] == config['ctm_params'][key], 'existing config[\"ctm_params\"] contains different hyperparameters'\n",
    "\n",
    "        # check whether the search_space is consistent with the config file\n",
    "        if 'sbert_params' in config['search_space']:\n",
    "            assert config['search_space']['sbert_params'].keys() == search_space_dict['sbert_params'].keys(), 'input search_space_dict[\"sbert_params\"] contains different hyperparameter keys than existing config[\"search_space\"][\"sbert_params\"]'\n",
    "            for k in search_space_dict['sbert_params'].keys():\n",
    "                assert k in config['search_space']['sbert_params'], f'input search_space_dict[\"sbert_params\"][\"{key}\"] contains value than existing config[\"search_space\"][\"sbert_params\"][\"{key}\"]'\n",
    "        if 'countvect_params' in config['search_space']:\n",
    "            assert config['search_space']['countvect_params'].keys() == search_space_dict['countvect_params'].keys(), 'input search_space_dict[\"countvect_params\"] contains different hyperparameter keys than existing config[\"search_space\"][\"countvect_params\"]'\n",
    "            for k in search_space_dict['countvect_params'].keys():\n",
    "                assert k in config['search_space']['countvect_params'], f'input search_space_dict[\"countvect_params\"][\"{key}\"] contains value than existing config[\"search_space\"][\"countvect_params\"][\"{key}\"]'\n",
    "        if 'ctm_params' in config['search_space']:\n",
    "            assert config['search_space']['ctm_params'].keys() == search_space_dict['ctm_params'].keys(), 'input search_space_dict[\"ctm_params\"] contains different hyperparameter keys than existing config[\"search_space\"][\"ctm_params\"]'\n",
    "            for k in search_space_dict['ctm_params'].keys():\n",
    "                assert k in config['search_space']['ctm_params'], f'input search_space_dict[\"ctm_params\"][\"{key}\"] contains value than existing config[\"search_space\"][\"ctm_params\"][\"{key}\"]'\n",
    "        \n",
    "        print('Loaded existing config file from {}'.format(config_path))\n",
    "        print('Hyperparameters and search space are consistent with the input parameters')\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_result_dict(result_path:Path, monitor_type:str):\n",
    "    if not result_path.exists():\n",
    "        result = {}\n",
    "\n",
    "        result['best_metric'] = -float('inf')\n",
    "        result['best_model_checkpoint'] = \"\"\n",
    "        result['best_hyperparameters'] = dict()\n",
    "        result[\"monitor_type\"] = monitor_type\n",
    "        result[\"log_history\"] = list()\n",
    "\n",
    "    else:\n",
    "        with open(result_path, 'r') as f:\n",
    "            result = json.load(f)\n",
    "\n",
    "        assert result['monitor_type'] == monitor_type\n",
    "\n",
    "        print('Loaded existing result file from {}'.format(result_path))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_ctm_model(model_checkpoint:Path, ctm_params:dict):\n",
    "\n",
    "    model_path = [p for p in model_checkpoint.iterdir() if p.is_dir()][-1]        # get the last dir (since there 's only one dir inside) -> get the only dir\n",
    "\n",
    "    # get the first file in the dir\n",
    "    epoch_file = [p for p in model_path.iterdir() if p.is_file()][0]\n",
    "    epoch_num = int(epoch_file.stem.split('_')[-1])\n",
    "\n",
    "    if 'hidden_sizes' in ctm_params:\n",
    "        ctm_params['hidden_sizes'] = tuple(ctm_params['hidden_sizes'])\n",
    "\n",
    "    ctm = CombinedTM(**ctm_params)\n",
    "\n",
    "    ctm.load(model_path, epoch_num)\n",
    "\n",
    "    return ctm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_topics(ctm, k=10):\n",
    "    return ctm.get_topic_lists(k)\n",
    "\n",
    "def _get_topic_word_metrix(ctm):\n",
    "    return ctm.get_topic_word_distribution()\n",
    "\n",
    "# ref: https://contextualized-topic-models.readthedocs.io/en/latest/readme.html (go to the section: Mono-Lingual Topic Modeling)\n",
    "# testing_dataset = qt.transform(text_for_contextual=testing_text_for_contextual, text_for_bow=testing_text_for_bow)\n",
    "# # n_sample how many times to sample the distribution (see the doc)\n",
    "# ctm.get_doc_topic_distribution(testing_dataset, n_samples=20) # returns a (n_documents, n_topics) matrix with the topic distribution of each document\n",
    "def _get_topic_document_metrix(ctm, dataset, n_samples=20):\n",
    "    return ctm.get_doc_topic_distribution(dataset, n_samples=n_samples).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def model_search(text_for_contextual, text_for_bow, hyperparameters:dict, search_space:dict, save_folder:Path,\n",
    "                 metrics:list[METRICS]=[METRICS.C_NPMI], monitor:METRICS=METRICS.C_NPMI, \n",
    "                 save_each_models=True, run_from_checkpoints=False,\n",
    "                 search_behaviour=SEARCH_BEHAVIOUR.GRID_SEARCH, search_rs=42, search_n_iter=10):\n",
    "    \n",
    "    config_json_path = save_folder.joinpath('config.json')\n",
    "    result_json_path = save_folder.joinpath('result.json')\n",
    "\n",
    "    if monitor not in metrics:\n",
    "        raise Exception('monitor is not in metrics. Please modify the metrics passed in.')\n",
    "\n",
    "    if run_from_checkpoints:\n",
    "        if not save_folder.exists():\n",
    "            print('Save folder:' + str(save_folder.resolve()) + ' does not exist. Function terminates.')\n",
    "            raise Exception('No checkpoints found. Function terminates.')\n",
    "        \n",
    "        # check for existing configs\n",
    "        if not config_json_path.exists():\n",
    "            raise Exception('No config.json found. Function terminates.')\n",
    "        \n",
    "        # check for existing results\n",
    "        if not result_json_path.exists():\n",
    "            print('no result.json is found. Assuming no existing checkpoints.')\n",
    "    else:\n",
    "        if save_folder.exists():\n",
    "            raise Exception('Checkpoints found. Please delete the checkpoints or set run_from_checkpoints=True. Function terminates.')\n",
    "\n",
    "    if not save_folder.exists():\n",
    "        save_folder.mkdir()\n",
    "\n",
    "    config = _init_config_dict(config_json_path, 'ctm', hyperparameters, search_space,\n",
    "                               metrics, monitor, search_behaviour, search_rs, search_n_iter)\n",
    "    result = _init_result_dict(result_json_path, monitor.value)\n",
    "\n",
    "    print('Search folder: {}'.format(save_folder))\n",
    "\n",
    "    # init\n",
    "    best_model_path = result['best_model_checkpoint']\n",
    "    best_metric_score = result['best_metric']\n",
    "    best_model = _load_ctm_model(Path(best_model_path),\n",
    "                                 result['best_hyperparameters']['ctm_params']) if best_model_path != \"\" else None\n",
    "    best_hyperparameters = result['best_hyperparameters']\n",
    "\n",
    "    print(f'Best model checkpoint: {best_model_path}')\n",
    "    print(f'Best metric score: {best_metric_score}')\n",
    "    print(f'Best model: {best_model}')\n",
    "\n",
    "    # search\n",
    "    # like bertopic, we create a temp dict for initiating the search space\n",
    "    # then we apply sklearn parameter sampler / parameter grid to get the search space\n",
    "    temp_search_space = {}\n",
    "    for k, v in search_space.items():\n",
    "        for kk, vv in v.items():\n",
    "            temp_search_space[k + '__' + kk] = vv\n",
    "\n",
    "    if search_behaviour == SEARCH_BEHAVIOUR.RANDOM_SEARCH:\n",
    "        search_iterator = ParameterSampler(temp_search_space, search_n_iter, random_state=search_rs)\n",
    "    elif search_behaviour == SEARCH_BEHAVIOUR.GRID_SEARCH:\n",
    "        search_iterator = ParameterGrid(temp_search_space)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    for search_space_dict in search_iterator:\n",
    "\n",
    "        # unwrap the search space dict\n",
    "\n",
    "        model_name = ''\n",
    "\n",
    "        _sbert_params = {}\n",
    "        _countvect_params = {}\n",
    "        _ctm_params = {}\n",
    "\n",
    "        for k, v in search_space_dict.items():\n",
    "            if k.startswith('sbert_params'):\n",
    "                _sbert_params[k.split('__')[1]] = v\n",
    "                model_name += 'sb_' + k.split('__')[1] + '_' + str(v) + '_'\n",
    "            elif k.startswith('countvect_params'):\n",
    "                _countvect_params[k.split('__')[1]] = v\n",
    "                model_name += 'cvect_' + k.split('__')[1] + '_' + str(v) + '_'\n",
    "            elif k.startswith('ctm_params'):\n",
    "                _ctm_params[k.split('__')[1]] = v\n",
    "                model_name += 'ctm_' + k.split('__')[1] + '_' + str(v) + '_'\n",
    "\n",
    "        model_name = model_name[:-1]     # remove the last '_'\n",
    "\n",
    "        model_path = save_folder.joinpath(config['model'] + '_' + model_name)\n",
    "\n",
    "        # check whether the model exists\n",
    "        if model_path.exists():\n",
    "            print('Skipping current search space: {}'.format(search_space_dict))\n",
    "            continue\n",
    "    \n",
    "        ##########\n",
    "        # Training starts\n",
    "        ##########\n",
    "\n",
    "        print('Current search space: {}'.format(search_space_dict))\n",
    "\n",
    "        sbert_params = deepcopy(config['sbert_params'])     # deepcopy just for safety (not messing up with the original config)\n",
    "        countvect_params = deepcopy(config['countvect_params'])\n",
    "        ctm_params = deepcopy(config['ctm_params'])\n",
    "\n",
    "        sbert_params.update(_sbert_params)\n",
    "        countvect_params.update(_countvect_params)\n",
    "        ctm_params.update(_ctm_params)\n",
    "\n",
    "        countvect_params['ngram_range'] = tuple(countvect_params['ngram_range'])     # convert list to tuple\n",
    "\n",
    "        # create bow\n",
    "        vectorizer = CountVectorizer(**countvect_params)\n",
    "        vectorizer.fit_transform(text_for_bow)\n",
    "        temp_vocabulary = set(vectorizer.get_feature_names_out())\n",
    "\n",
    "        preprocessed_docs_tmp = [' '.join([w for w in doc.split() if w in temp_vocabulary])\n",
    "                            for doc in text_for_bow]\n",
    "        text_for_bow = preprocessed_docs_tmp\n",
    "    \n",
    "        # create sbert embeddings\n",
    "        if platform.system() == 'Linux' or platform.system() == 'Windows':\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            device = torch.device('mps')        # m-series machine\n",
    "        \n",
    "        tp = TopicModelDataPreparation()\n",
    "\n",
    "        # check existing embeddings\n",
    "        # reuse them if found\n",
    "        embeddings_path = save_folder.joinpath(f'embeddings_{sbert_params[\"model_name_or_path\"]}.pkl')\n",
    "        if embeddings_path.exists():\n",
    "            with open(embeddings_path, 'rb') as f:\n",
    "                embeddings = np.load(f)\n",
    "\n",
    "            print(f'Found existing sbert embeddings at {embeddings_path}. Reusing them.')\n",
    "        else:\n",
    "            embeddings = bert_embeddings_from_list(text_for_contextual, **sbert_params, device=device)\n",
    "\n",
    "            with open(embeddings_path, 'wb') as f:\n",
    "                np.save(f, embeddings)\n",
    "         \n",
    "        training_dataset = tp.fit(text_for_contextual=text_for_contextual, text_for_bow=text_for_bow, custom_embeddings=embeddings)\n",
    "\n",
    "        # ctm\n",
    "\n",
    "        ctm_params['bow_size'] = len(tp.vocab)\n",
    "        ctm_params['contextual_size'] = embeddings.shape[1]\n",
    "        ctm_params['hidden_sizes'] = tuple(ctm_params['hidden_sizes'])     # convert list to tuple\n",
    "\n",
    "        ctm = CombinedTM(**ctm_params)\n",
    "        ctm.device = device\n",
    "        ctm.fit(training_dataset, verbose=True)\n",
    "\n",
    "        ##########\n",
    "        # Training ends\n",
    "        ##########\n",
    "\n",
    "        ##########\n",
    "        # Evaluation starts\n",
    "        ##########\n",
    "\n",
    "        # init data for gensim coherence model\n",
    "        topic_words = _get_topics(ctm, k=10)\n",
    "        topics = ctm.get_predicted_topics(training_dataset, n_samples=20)\n",
    "\n",
    "        documents = pd.DataFrame({\"Document\": X,\n",
    "                                \"ID\": range(len(X)),\n",
    "                                \"Topic\": topics})\n",
    "        \n",
    "        docs_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
    "        texts = [doc.split() for doc in docs_per_topic.Document.values]\n",
    "        \n",
    "        dictionary = corpora.Dictionary(texts)\n",
    "        corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "        # init octis format result for convenience\n",
    "        result_octis = {}\n",
    "        result_octis['topics'] = topic_words\n",
    "        result_octis['topic-word-matrix'] = _get_topic_word_metrix(ctm)\n",
    "        result_octis['topic-document-matrix'] = _get_topic_document_metrix(ctm, training_dataset, n_samples=20)\n",
    "\n",
    "        print('Compute evaluation metrics')\n",
    "\n",
    "        metrics_score = dict()\n",
    "\n",
    "        for metric in metrics:\n",
    "            if metric in COHERENCE_MODEL_METRICS:\n",
    "                coherencemodel = CoherenceModel(topics=topic_words, texts=texts, corpus=corpus, dictionary=dictionary, topn=10, coherence=metric.value)\n",
    "                score = coherencemodel.get_coherence()\n",
    "            elif metric == METRICS.TOPIC_DIVERSITY:\n",
    "                score = compute_topic_diversity(result_octis, topk=10)\n",
    "            elif metric == METRICS.INVERTED_RBO:\n",
    "                score = compute_inverted_rbo(result_octis, topk=10)\n",
    "            elif metric == METRICS.PAIRWISE_JACCARD_SIMILARITY:\n",
    "                score = compute_pairwise_jaccard_similarity(result_octis, topk=10)\n",
    "            else:\n",
    "                raise Exception('Unknown metric: {}'.format(metric.value))\n",
    "\n",
    "            metrics_score[metric.value] = score\n",
    "\n",
    "            print(f'Evaluation metric ({metric.value}): {score}')\n",
    "\n",
    "        monitor_score = metrics_score[monitor.value]\n",
    "\n",
    "        ##########\n",
    "        # Evaluation ends\n",
    "        ##########\n",
    "\n",
    "        ##########\n",
    "        # Save models\n",
    "        ##########\n",
    "\n",
    "        if not model_path.exists():\n",
    "            model_path.mkdir()\n",
    "        \n",
    "        if save_each_models:\n",
    "            ctm.save(models_dir=model_path)\n",
    "\n",
    "        ##########\n",
    "        # Save models ends\n",
    "        ##########\n",
    "\n",
    "        ###########\n",
    "        # Update result dict and json file\n",
    "        ###########\n",
    "            \n",
    "        model_hyperparameters = {\n",
    "            'sbert_params': sbert_params,\n",
    "            'countvect_params': countvect_params,\n",
    "            'ctm_params': ctm_params\n",
    "        }\n",
    "\n",
    "        if monitor_score > best_metric_score:\n",
    "            best_metric_score = monitor_score\n",
    "            best_model_path = model_path\n",
    "            best_model = ctm\n",
    "            best_hyperparameters = model_hyperparameters\n",
    "\n",
    "        model_log_history = dict()\n",
    "        model_log_history.update(metrics_score)\n",
    "        model_log_history['model_name'] = model_name\n",
    "        model_log_history['hyperparameters']  = model_hyperparameters\n",
    "\n",
    "        result['best_metric'] = best_metric_score\n",
    "        result['best_model_checkpoint'] = str(best_model_path)\n",
    "        result['best_hyperparameters'] = best_hyperparameters\n",
    "        result['log_history'].append(model_log_history)\n",
    "\n",
    "        # save result\n",
    "        with open(result_json_path, 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        print('Saved result.json at:', result_json_path)\n",
    "        print('\\n\\n')\n",
    "    \n",
    "    print('Search ends')\n",
    "    return best_model, best_model_path, best_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing config file from ctm_random_search_20240123_002111/config.json\n",
      "Hyperparameters and search space are consistent with the input parameters\n",
      "Loaded existing result file from ctm_random_search_20240123_002111/result.json\n",
      "Search folder: ctm_random_search_20240123_002111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:669: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model checkpoint: ctm_random_search_20240123_002111/ctmsb_model_name_or_path_all-mpnet-base-v2_ctm_num_epochs_100_ctm_n_components_10_ctm_hidden_sizes_(200, 200)_cvect_ngram_range_[1, 2]_cvect_max_features_2500\n",
      "Best metric score: -0.01634058093071984\n",
      "Best model: <contextualized_topic_models.models.ctm.CombinedTM object at 0x7fc678128970>\n",
      "\n",
      "\n",
      "Skipping current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n",
      "Skipping current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n",
      "Skipping current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2500}\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n",
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 126.15193300514125\tTime: 0:00:04.192255: : 20it [01:23,  4.18s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 532.38it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 517.09it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 467.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.022405069062131307\n",
      "Evaluation metric (c_v): 0.4419939284615909\n",
      "Evaluation metric (u_mass): -0.06146510052604809\n",
      "Evaluation metric (c_uci): -1.4714216072126418\n",
      "Evaluation metric (topic_diversity): 0.65\n",
      "Evaluation metric (inverted_rbo): 0.9430718514006015\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.04013869913332188\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 117.76040749715688\tTime: 0:00:04.184945: : 20it [01:25,  4.27s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 529.85it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 490.01it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 458.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.04352667736457535\n",
      "Evaluation metric (c_v): 0.42423206005821656\n",
      "Evaluation metric (u_mass): -0.019025505205554096\n",
      "Evaluation metric (c_uci): -1.7152795169878814\n",
      "Evaluation metric (topic_diversity): 0.78\n",
      "Evaluation metric (inverted_rbo): 0.9480674231792063\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03350915414898903\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 119.77782767621818\tTime: 0:00:04.175240: : 50it [03:29,  4.19s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 504.48it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 495.38it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 458.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.0038959708568421765\n",
      "Evaluation metric (c_v): 0.4592628621951394\n",
      "Evaluation metric (u_mass): -0.05179622466306812\n",
      "Evaluation metric (c_uci): -0.8297934674912829\n",
      "Evaluation metric (topic_diversity): 0.66\n",
      "Evaluation metric (inverted_rbo): 0.9418689357324812\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.04193753216891557\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 119.68527478581268\tTime: 0:00:04.169416: : 100it [06:54,  4.15s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 547.51it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 504.95it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 441.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.0013471877673410717\n",
      "Evaluation metric (c_v): 0.4523692709936279\n",
      "Evaluation metric (u_mass): -0.05910723233979739\n",
      "Evaluation metric (c_uci): -0.9773590596372734\n",
      "Evaluation metric (topic_diversity): 0.695\n",
      "Evaluation metric (inverted_rbo): 0.9539896136411654\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.030547408252312915\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 117.36041986467072\tTime: 0:00:04.110979: : 100it [06:50,  4.10s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 541.79it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 509.30it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 463.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.0192228713780478\n",
      "Evaluation metric (c_v): 0.4450774459410975\n",
      "Evaluation metric (u_mass): -0.013657520976097764\n",
      "Evaluation metric (c_uci): -1.3314279432494813\n",
      "Evaluation metric (topic_diversity): 0.78\n",
      "Evaluation metric (inverted_rbo): 0.9562870317692064\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.036043267209417876\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 111.2839107950225\tTime: 0:00:04.163022: : 100it [06:52,  4.12s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 527.07it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 495.09it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 437.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.001214901179241406\n",
      "Evaluation metric (c_v): 0.4508387659963097\n",
      "Evaluation metric (u_mass): -0.01881238888919292\n",
      "Evaluation metric (c_uci): -0.7483445329354885\n",
      "Evaluation metric (topic_diversity): 0.84\n",
      "Evaluation metric (inverted_rbo): 0.9665107370471429\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.02231968810916179\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.33553580170066\tTime: 0:00:04.067451: : 50it [03:20,  4.01s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 549.32it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 521.81it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 454.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.0069130114568306065\n",
      "Evaluation metric (c_v): 0.44536760339716785\n",
      "Evaluation metric (u_mass): -0.004576176553609037\n",
      "Evaluation metric (c_uci): -0.5714438586053755\n",
      "Evaluation metric (topic_diversity): 0.87\n",
      "Evaluation metric (inverted_rbo): 0.9722331117749207\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.01572449642625081\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 114.14193633696708\tTime: 0:00:04.055095: : 20it [01:21,  4.08s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 533.23it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 529.94it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 461.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.016800113313361124\n",
      "Evaluation metric (c_v): 0.4387913385990032\n",
      "Evaluation metric (u_mass): -0.043650357204819454\n",
      "Evaluation metric (c_uci): -1.1782658869876705\n",
      "Evaluation metric (topic_diversity): 0.675\n",
      "Evaluation metric (inverted_rbo): 0.9350703618463534\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.04087657223554241\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.77651998893602\tTime: 0:00:04.103952: : 50it [03:25,  4.10s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 519.71it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 498.58it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 463.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.015737983468166548\n",
      "Evaluation metric (c_v): 0.4315667794612296\n",
      "Evaluation metric (u_mass): -0.055752366846366086\n",
      "Evaluation metric (c_uci): -1.1907935052385212\n",
      "Evaluation metric (topic_diversity): 0.685\n",
      "Evaluation metric (inverted_rbo): 0.9378375655442481\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03683596245515749\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.32729080433154\tTime: 0:00:03.972438: : 50it [03:19,  3.99s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 549.91it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 535.61it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 461.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.0018944893303838076\n",
      "Evaluation metric (c_v): 0.45132304291340297\n",
      "Evaluation metric (u_mass): -0.042937292247730505\n",
      "Evaluation metric (c_uci): -0.8496342541925961\n",
      "Evaluation metric (topic_diversity): 0.725\n",
      "Evaluation metric (inverted_rbo): 0.9550105533607894\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.026016149765538715\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.33361884999618\tTime: 0:00:04.191064: : 50it [03:27,  4.15s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 532.25it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 498.75it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 450.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.00013579196930781635\n",
      "Evaluation metric (c_v): 0.44945925055420144\n",
      "Evaluation metric (u_mass): -0.02229281110424119\n",
      "Evaluation metric (c_uci): -0.6195682868039065\n",
      "Evaluation metric (topic_diversity): 0.83\n",
      "Evaluation metric (inverted_rbo): 0.9579776837163492\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.02769368956159462\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.47237584548445\tTime: 0:00:04.021507: : 50it [03:20,  4.00s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 533.01it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 518.14it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 459.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.011210547256574265\n",
      "Evaluation metric (c_v): 0.4619663153040821\n",
      "Evaluation metric (u_mass): -0.03668040412604955\n",
      "Evaluation metric (c_uci): -0.6285594072616103\n",
      "Evaluation metric (topic_diversity): 0.73\n",
      "Evaluation metric (inverted_rbo): 0.9495193197523685\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.02783661941230785\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.28803524635322\tTime: 0:00:04.045146: : 20it [01:22,  4.11s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 541.35it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 528.13it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 569.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.018666471353272217\n",
      "Evaluation metric (c_v): 0.444103763632757\n",
      "Evaluation metric (u_mass): -0.024832325876313777\n",
      "Evaluation metric (c_uci): -1.1985277567980381\n",
      "Evaluation metric (topic_diversity): 0.83\n",
      "Evaluation metric (inverted_rbo): 0.969971255183492\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.023720521346940332\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 111.08086212455872\tTime: 0:00:03.970094: : 100it [06:42,  4.03s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 550.97it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 515.44it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 464.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.0161712746142729\n",
      "Evaluation metric (c_v): 0.42029838281860277\n",
      "Evaluation metric (u_mass): -0.006917521346000735\n",
      "Evaluation metric (c_uci): -0.9305043320777239\n",
      "Evaluation metric (topic_diversity): 0.83\n",
      "Evaluation metric (inverted_rbo): 0.9650282144271428\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.023284791499445786\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.55763553299067\tTime: 0:00:04.124515: : 50it [03:24,  4.08s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 539.27it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 523.97it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 468.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.0031875715066945927\n",
      "Evaluation metric (c_v): 0.45575823146739414\n",
      "Evaluation metric (u_mass): -0.05099697190384954\n",
      "Evaluation metric (c_uci): -0.7797572280000715\n",
      "Evaluation metric (topic_diversity): 0.695\n",
      "Evaluation metric (inverted_rbo): 0.9476642395323308\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03179801930005611\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.2379905823634\tTime: 0:00:04.291360: : 50it [03:27,  4.15s/it] \n",
      "100%|██████████| 1180/1180 [00:02<00:00, 528.37it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 501.19it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 576.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.005789096531604772\n",
      "Evaluation metric (c_v): 0.44299375250622897\n",
      "Evaluation metric (u_mass): -0.028211090371161374\n",
      "Evaluation metric (c_uci): -0.6535050869151682\n",
      "Evaluation metric (topic_diversity): 0.695\n",
      "Evaluation metric (inverted_rbo): 0.9518340208389474\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03113989824923505\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.3273397903507\tTime: 0:00:04.116747: : 50it [03:25,  4.11s/it] \n",
      "100%|██████████| 1180/1180 [00:02<00:00, 525.24it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 499.34it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 505.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.015165863818045577\n",
      "Evaluation metric (c_v): 0.4314557890093694\n",
      "Evaluation metric (u_mass): -0.025535564791045285\n",
      "Evaluation metric (c_uci): -1.0552583752442448\n",
      "Evaluation metric (topic_diversity): 0.83\n",
      "Evaluation metric (inverted_rbo): 0.9595603114292064\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.02665405343423919\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.14263188990624\tTime: 0:00:04.164387: : 50it [03:27,  4.14s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 525.48it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 499.31it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 455.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.01656921340935488\n",
      "Evaluation metric (c_v): 0.4375067561647626\n",
      "Evaluation metric (u_mass): -0.022840284186458996\n",
      "Evaluation metric (c_uci): -1.1264110050692921\n",
      "Evaluation metric (topic_diversity): 0.81\n",
      "Evaluation metric (inverted_rbo): 0.9559098492963493\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.02974047318732561\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.4479065459092\tTime: 0:00:04.070344: : 20it [01:24,  4.24s/it] \n",
      "100%|██████████| 1180/1180 [00:02<00:00, 532.09it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 512.10it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 436.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.02139352754301036\n",
      "Evaluation metric (c_v): 0.43796317859183437\n",
      "Evaluation metric (u_mass): -0.02759162162084256\n",
      "Evaluation metric (c_uci): -1.1933083732458594\n",
      "Evaluation metric (topic_diversity): 0.77\n",
      "Evaluation metric (inverted_rbo): 0.9428515141353968\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.036437771989887575\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 110.91769171691325\tTime: 0:00:04.152519: : 100it [06:43,  4.04s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 517.06it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 504.26it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 439.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.023362142308020507\n",
      "Evaluation metric (c_v): 0.4243728398973595\n",
      "Evaluation metric (u_mass): -0.02869039176249688\n",
      "Evaluation metric (c_uci): -1.3099561360388934\n",
      "Evaluation metric (topic_diversity): 0.84\n",
      "Evaluation metric (inverted_rbo): 0.9663859486120635\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.024236517218973356\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 113.09362611131611\tTime: 0:00:04.155997: : 100it [06:56,  4.17s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 518.48it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 513.37it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 448.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.008683610296622141\n",
      "Evaluation metric (c_v): 0.4481908934759118\n",
      "Evaluation metric (u_mass): -0.06271357803975869\n",
      "Evaluation metric (c_uci): -1.110290614224168\n",
      "Evaluation metric (topic_diversity): 0.695\n",
      "Evaluation metric (inverted_rbo): 0.9431117823273308\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03353475277460937\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.27209011915885\tTime: 0:00:04.058103: : 20it [01:22,  4.11s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 518.53it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 501.29it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 447.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.033667088022001086\n",
      "Evaluation metric (c_v): 0.41472769598233683\n",
      "Evaluation metric (u_mass): -0.0479807676554168\n",
      "Evaluation metric (c_uci): -1.3417423817895242\n",
      "Evaluation metric (topic_diversity): 0.81\n",
      "Evaluation metric (inverted_rbo): 0.953935299950635\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03412643809960631\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 113.26561937663796\tTime: 0:00:04.007417: : 100it [06:42,  4.03s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 531.20it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 510.88it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 460.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.0007882726820865948\n",
      "Evaluation metric (c_v): 0.44965085303056956\n",
      "Evaluation metric (u_mass): -0.03385625905630996\n",
      "Evaluation metric (c_uci): -0.8895163721623959\n",
      "Evaluation metric (topic_diversity): 0.7\n",
      "Evaluation metric (inverted_rbo): 0.9550669426948872\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.029244849442014168\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.39269967115563\tTime: 0:00:04.373333: : 50it [03:28,  4.18s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 528.48it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 515.79it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 455.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.014847039855361576\n",
      "Evaluation metric (c_v): 0.45603220048038046\n",
      "Evaluation metric (u_mass): -0.05065805084029875\n",
      "Evaluation metric (c_uci): -0.47085914305878046\n",
      "Evaluation metric (topic_diversity): 0.67\n",
      "Evaluation metric (inverted_rbo): 0.9418049665372557\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.035002625242155944\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.06883618303837\tTime: 0:00:04.037958: : 50it [03:23,  4.06s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 512.47it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 501.43it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 451.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.024995489289709016\n",
      "Evaluation metric (c_v): 0.42694906694498613\n",
      "Evaluation metric (u_mass): -0.0467620040398521\n",
      "Evaluation metric (c_uci): -1.2724980375429022\n",
      "Evaluation metric (topic_diversity): 0.85\n",
      "Evaluation metric (inverted_rbo): 0.9713725201806349\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.021020142949967506\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.00241719149653\tTime: 0:00:04.028245: : 50it [03:21,  4.03s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 523.43it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 514.06it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 448.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.0020837911113456425\n",
      "Evaluation metric (c_v): 0.4658087600485712\n",
      "Evaluation metric (u_mass): -0.025566932790549207\n",
      "Evaluation metric (c_uci): -0.7662948795469878\n",
      "Evaluation metric (topic_diversity): 0.87\n",
      "Evaluation metric (inverted_rbo): 0.9726540724992063\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.018499407560295073\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.15640762238506\tTime: 0:00:03.975164: : 20it [01:20,  4.04s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 527.43it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 512.76it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 449.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.019778167212297092\n",
      "Evaluation metric (c_v): 0.4446891916490384\n",
      "Evaluation metric (u_mass): -0.02157180705509547\n",
      "Evaluation metric (c_uci): -1.158705397171771\n",
      "Evaluation metric (topic_diversity): 0.86\n",
      "Evaluation metric (inverted_rbo): 0.9661600463806349\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.021975690861139777\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 111.15944916884509\tTime: 0:00:04.165466: : 100it [06:48,  4.08s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 497.29it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 490.70it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 417.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.011382675764187427\n",
      "Evaluation metric (c_v): 0.43942880658097766\n",
      "Evaluation metric (u_mass): -0.004106981862058852\n",
      "Evaluation metric (c_uci): -0.9612329666000606\n",
      "Evaluation metric (topic_diversity): 0.79\n",
      "Evaluation metric (inverted_rbo): 0.9575633490592064\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.034393644042766854\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 111.02212079204271\tTime: 0:00:04.211622: : 100it [07:08,  4.28s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 515.80it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 496.44it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 446.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.03618487887589\n",
      "Evaluation metric (c_v): 0.4292095359200562\n",
      "Evaluation metric (u_mass): -0.0353391678546612\n",
      "Evaluation metric (c_uci): -1.6627652767764478\n",
      "Evaluation metric (topic_diversity): 0.84\n",
      "Evaluation metric (inverted_rbo): 0.963482413043492\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.028357658853014885\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 113.32740183822982\tTime: 0:00:04.245882: : 100it [06:52,  4.12s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 507.80it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 509.86it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 566.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.0119485099451722\n",
      "Evaluation metric (c_v): 0.4360222856552113\n",
      "Evaluation metric (u_mass): -0.06913261207922486\n",
      "Evaluation metric (c_uci): -1.1360586728930935\n",
      "Evaluation metric (topic_diversity): 0.665\n",
      "Evaluation metric (inverted_rbo): 0.9417348163224812\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.038035530996260954\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.50896870594494\tTime: 0:00:04.604682: : 50it [03:32,  4.26s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 516.13it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 505.99it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 433.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.0008543689740492539\n",
      "Evaluation metric (c_v): 0.43594910447325363\n",
      "Evaluation metric (u_mass): -0.04147507298165241\n",
      "Evaluation metric (c_uci): -0.7805076860376771\n",
      "Evaluation metric (topic_diversity): 0.665\n",
      "Evaluation metric (inverted_rbo): 0.9413739278497368\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03617855267684173\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.17671617761924\tTime: 0:00:04.251412: : 50it [03:31,  4.24s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 505.73it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 438.04it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 447.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.024900778529041958\n",
      "Evaluation metric (c_v): 0.42354619492206497\n",
      "Evaluation metric (u_mass): -0.032610879085398586\n",
      "Evaluation metric (c_uci): -1.1229607797220156\n",
      "Evaluation metric (topic_diversity): 0.8\n",
      "Evaluation metric (inverted_rbo): 0.9579812121477778\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03132286052822689\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.23390872039666\tTime: 0:00:04.241204: : 20it [01:23,  4.18s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 518.18it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 506.27it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 450.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.01582852242098282\n",
      "Evaluation metric (c_v): 0.4299724451643674\n",
      "Evaluation metric (u_mass): -0.025581771002452236\n",
      "Evaluation metric (c_uci): -0.9970560482768305\n",
      "Evaluation metric (topic_diversity): 0.84\n",
      "Evaluation metric (inverted_rbo): 0.9611506545749207\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.022527997553797353\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.14201096137568\tTime: 0:00:04.139123: : 50it [03:31,  4.23s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 516.27it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 498.06it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 420.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.005296554119026634\n",
      "Evaluation metric (c_v): 0.44053318198163094\n",
      "Evaluation metric (u_mass): -0.016771171647793837\n",
      "Evaluation metric (c_uci): -0.8217342930067375\n",
      "Evaluation metric (topic_diversity): 0.83\n",
      "Evaluation metric (inverted_rbo): 0.962464734793492\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.026770630279402206\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 113.24775143171186\tTime: 0:00:04.228096: : 100it [07:01,  4.22s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 516.51it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 492.86it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 431.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.013643061901091168\n",
      "Evaluation metric (c_v): 0.4411398566738045\n",
      "Evaluation metric (u_mass): -0.050770121564050266\n",
      "Evaluation metric (c_uci): -1.2554657063042132\n",
      "Evaluation metric (topic_diversity): 0.73\n",
      "Evaluation metric (inverted_rbo): 0.9535994983431579\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.027554179566563454\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 113.30175669300445\tTime: 0:00:03.996523: : 100it [06:42,  4.02s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 522.48it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 526.65it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 458.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.004025450633727128\n",
      "Evaluation metric (c_v): 0.4519716532098581\n",
      "Evaluation metric (u_mass): -0.052269215945936046\n",
      "Evaluation metric (c_uci): -0.7581013176115248\n",
      "Evaluation metric (topic_diversity): 0.695\n",
      "Evaluation metric (inverted_rbo): 0.9509793937574436\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03024987749201533\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.09048830765198\tTime: 0:00:04.116330: : 50it [03:24,  4.08s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 523.78it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 500.73it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 452.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.002517379442514077\n",
      "Evaluation metric (c_v): 0.44350202397185406\n",
      "Evaluation metric (u_mass): -0.045635050597720314\n",
      "Evaluation metric (c_uci): -0.7750037648537296\n",
      "Evaluation metric (topic_diversity): 0.69\n",
      "Evaluation metric (inverted_rbo): 0.9459110708032706\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03524432857168718\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 113.052032192447\tTime: 0:00:04.026962: : 50it [03:22,  4.04s/it]  \n",
      "100%|██████████| 1180/1180 [00:02<00:00, 522.76it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 506.72it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 436.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.00888411651333724\n",
      "Evaluation metric (c_v): 0.4599606751703931\n",
      "Evaluation metric (u_mass): -0.04630400562683048\n",
      "Evaluation metric (c_uci): -0.671891483030875\n",
      "Evaluation metric (topic_diversity): 0.73\n",
      "Evaluation metric (inverted_rbo): 0.9541273685609775\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.027604873897850928\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.10146308814802\tTime: 0:00:04.049318: : 50it [03:24,  4.09s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 532.05it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 508.88it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 572.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.006579957678364714\n",
      "Evaluation metric (c_v): 0.44612087880452556\n",
      "Evaluation metric (u_mass): -0.014379631270424877\n",
      "Evaluation metric (c_uci): -0.6642249422064144\n",
      "Evaluation metric (topic_diversity): 0.87\n",
      "Evaluation metric (inverted_rbo): 0.9733929346057143\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.017046974735313226\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 113.20137333243049\tTime: 0:00:04.112963: : 100it [06:48,  4.09s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 516.07it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 504.16it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 434.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.0008797719700542224\n",
      "Evaluation metric (c_v): 0.46416128305194365\n",
      "Evaluation metric (u_mass): -0.05589096071060153\n",
      "Evaluation metric (c_uci): -0.9790589704979864\n",
      "Evaluation metric (topic_diversity): 0.745\n",
      "Evaluation metric (inverted_rbo): 0.9620784800721804\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.023910071877319725\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.27972256156526\tTime: 0:00:04.247542: : 20it [01:23,  4.16s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 524.70it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 501.12it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 440.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.003139562747977248\n",
      "Evaluation metric (c_v): 0.43973717433523374\n",
      "Evaluation metric (u_mass): -0.01585013590048491\n",
      "Evaluation metric (c_uci): -0.46399260198878095\n",
      "Evaluation metric (topic_diversity): 0.8\n",
      "Evaluation metric (inverted_rbo): 0.950922654147619\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.03141077093605474\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 113.73916451257604\tTime: 0:00:04.128098: : 20it [01:22,  4.14s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 516.68it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 499.33it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 450.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.016652439399946654\n",
      "Evaluation metric (c_v): 0.43360865706880025\n",
      "Evaluation metric (u_mass): -0.054498632486339224\n",
      "Evaluation metric (c_uci): -1.145853102346401\n",
      "Evaluation metric (topic_diversity): 0.645\n",
      "Evaluation metric (inverted_rbo): 0.9325892246204135\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.04199908957119319\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 112.86371176722092\tTime: 0:00:04.158859: : 100it [06:44,  4.04s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 530.10it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 520.99it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 455.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.024055018223118688\n",
      "Evaluation metric (c_v): 0.4412536736182925\n",
      "Evaluation metric (u_mass): -0.1147810306482672\n",
      "Evaluation metric (c_uci): -1.5641806037982606\n",
      "Evaluation metric (topic_diversity): 0.7\n",
      "Evaluation metric (inverted_rbo): 0.9587390073157519\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.0304858508500353\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100, 100), 'countvect_params__ngram_range': [1, 1], 'countvect_params__max_features': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.36397520781979\tTime: 0:00:04.185548: : 20it [01:22,  4.14s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 513.28it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 505.90it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 457.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.029446820934948898\n",
      "Evaluation metric (c_v): 0.41376924044215524\n",
      "Evaluation metric (u_mass): -0.023800787725279954\n",
      "Evaluation metric (c_uci): -1.3212243579927894\n",
      "Evaluation metric (topic_diversity): 0.81\n",
      "Evaluation metric (inverted_rbo): 0.9542839264392063\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.0307055765776096\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 50, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [50/50]\t Seen Samples: [3772800/3774950]\tTrain Loss: 111.00010600263937\tTime: 0:00:03.976478: : 50it [03:21,  4.03s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 525.28it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 507.58it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 453.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.007796926318669045\n",
      "Evaluation metric (c_v): 0.4346345721731887\n",
      "Evaluation metric (u_mass): -0.055355372647268565\n",
      "Evaluation metric (c_uci): -0.9687860259198329\n",
      "Evaluation metric (topic_diversity): 0.84\n",
      "Evaluation metric (inverted_rbo): 0.9663677034992063\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.02491877842755036\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-mpnet-base-v2', 'ctm_params__num_epochs': 20, 'ctm_params__n_components': 10, 'ctm_params__hidden_sizes': (100, 100), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-mpnet-base-v2.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 10\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.9\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (100, 100)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [1509120/1509980]\tTrain Loss: 111.31449293180276\tTime: 0:00:03.990766: : 20it [01:21,  4.09s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 533.59it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 516.20it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 440.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): -0.010799783589159314\n",
      "Evaluation metric (c_v): 0.436333377235598\n",
      "Evaluation metric (u_mass): -0.01311349848400469\n",
      "Evaluation metric (c_uci): -0.8855430237827646\n",
      "Evaluation metric (topic_diversity): 0.81\n",
      "Evaluation metric (inverted_rbo): 0.9527252665606349\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.02945763100561862\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Current search space: {'sbert_params__model_name_or_path': 'all-roberta-large-v1', 'ctm_params__num_epochs': 100, 'ctm_params__n_components': 20, 'ctm_params__hidden_sizes': (200, 200), 'countvect_params__ngram_range': [1, 2], 'countvect_params__max_features': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing sbert embeddings at ctm_random_search_20240123_002111/embeddings_all-roberta-large-v1.pkl. Reusing them.\n",
      "Settings: \n",
      "                   N Components: 20\n",
      "                   Topic Prior Mean: 0.0\n",
      "                   Topic Prior Variance: 0.95\n",
      "                   Model Type: prodLDA\n",
      "                   Hidden Sizes: (200, 200)\n",
      "                   Activation: softplus\n",
      "                   Dropout: 0.2\n",
      "                   Learn Priors: True\n",
      "                   Learning Rate: 0.002\n",
      "                   Momentum: 0.99\n",
      "                   Reduce On Plateau: False\n",
      "                   Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]\t Seen Samples: [7545600/7549900]\tTrain Loss: 112.92632984164612\tTime: 0:00:03.994332: : 100it [06:46,  4.07s/it]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 517.85it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 497.93it/s]\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 564.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute evaluation metrics\n",
      "Evaluation metric (c_npmi): 0.0033628898156659497\n",
      "Evaluation metric (c_v): 0.464137135987051\n",
      "Evaluation metric (u_mass): -0.04618440021873823\n",
      "Evaluation metric (c_uci): -0.9267832903431461\n",
      "Evaluation metric (topic_diversity): 0.76\n",
      "Evaluation metric (inverted_rbo): 0.9659142649526692\n",
      "Evaluation metric (pairwise_jaccard_similarity): 0.020351058244165637\n",
      "Saved result.json at: ctm_random_search_20240123_002111/result.json\n",
      "\n",
      "\n",
      "\n",
      "Search ends\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# grid search / random search\n",
    "\n",
    "# hyperparameters\n",
    "sbert_params = _init_sbert_params(model_name_or_path='all-mpnet-base-v2')\n",
    "countvect_params = _init_count_vectorizer_params(max_features=2000, ngram_range=(1,1))\n",
    "ctm_params = _init_ctm_params(n_components=10, hidden_sizes=(100, 100), dropout=0.2, lr=2e-3, momentum=0.99, solver=\"adam\", num_epochs=20)\n",
    "\n",
    "search_space_dict = {\n",
    "    'sbert_params': {\n",
    "        'model_name_or_path': ['all-mpnet-base-v2', 'all-roberta-large-v1']\n",
    "    },\n",
    "    'countvect_params': {\n",
    "        'max_features' : [1500, 2000, 2500],\n",
    "        'ngram_range': [[1, 1], [1, 2]]     # datatype is list as json does not support tuple\n",
    "    },\n",
    "    'ctm_params':{\n",
    "        'n_components': [10, 20],\n",
    "        'hidden_sizes': [(100, 100), (200, 200), (100, 100, 100), (200, 200, 200)],\n",
    "        'num_epochs':[20, 50, 100]\n",
    "    }\n",
    "}\n",
    "\n",
    "# search_behaviour = SEARCH_BEHAVIOUR.GRID_SEARCH\n",
    "search_behaviour = SEARCH_BEHAVIOUR.RANDOM_SEARCH\n",
    "\n",
    "# training_datetime = datetime.now()\n",
    "training_datetime = datetime(2024, 1, 23, 0, 21, 11)\n",
    "training_folder = Path(f'ctm_{search_behaviour.value}_{training_datetime.strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "\n",
    "best_model, best_model_path, best_hyperparameters = model_search(\n",
    "    X,\n",
    "    X_preprocessed,\n",
    "    hyperparameters={\n",
    "        'sbert_params': sbert_params,\n",
    "        'countvect_params': countvect_params,\n",
    "        'ctm_params': ctm_params\n",
    "    },\n",
    "    search_space=search_space_dict,\n",
    "    save_folder=training_folder,\n",
    "    metrics=[METRICS.C_NPMI, METRICS.C_V, METRICS.UMASS, METRICS.C_UCI, METRICS.TOPIC_DIVERSITY, METRICS.INVERTED_RBO, METRICS.PAIRWISE_JACCARD_SIMILARITY],\n",
    "    monitor=METRICS.C_NPMI,\n",
    "    save_each_models=True,\n",
    "    run_from_checkpoints=True,\n",
    "    search_behaviour=search_behaviour,\n",
    "    search_rs=42,\n",
    "    search_n_iter=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/contextualized_topic_models/models/ctm.py:669: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load the best model from the checkpoints\n",
    "\n",
    "search_behaviour = SEARCH_BEHAVIOUR.GRID_SEARCH\n",
    "training_datetime = datetime(2024, 1, 22, 16, 6, 40)\n",
    "training_folder = Path(f'ctm_{search_behaviour.value}_{training_datetime.strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "\n",
    "training_result_json_path = training_folder.joinpath('result.json')\n",
    "with open(training_result_json_path, 'r') as f:\n",
    "    training_result = json.load(f)\n",
    "\n",
    "\n",
    "# load the embeddings\n",
    "model_name_or_path = training_result['best_hyperparameters']['sbert_params']['model_name_or_path']\n",
    "embeddings_path = training_folder.joinpath(f'embeddings_{model_name_or_path}.pkl')\n",
    "with open(embeddings_path, 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "\n",
    "best_model_path = training_result['best_model_checkpoint']\n",
    "ctm_hyperparameters = training_result['best_hyperparameters']['ctm_params']\n",
    "\n",
    "ctm_hyperparameters['bow_size'] = 2000\n",
    "ctm_hyperparameters['contextual_size'] = 768\n",
    "\n",
    "# best_model_path = [p for p in Path(best_model_path).iterdir() if p.is_dir()][-1]        # get the last dir (since there 's only one dir inside) -> get the only dir\n",
    "\n",
    "best_model = _load_ctm_model(Path(best_model_path), ctm_hyperparameters, epoch=99)\n",
    "topic_lists = best_model.get_topic_lists(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content',\n",
       " 'update',\n",
       " 'game',\n",
       " 'hour',\n",
       " 'new',\n",
       " 'one',\n",
       " 'time',\n",
       " 'developer',\n",
       " 'play',\n",
       " 'still']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_lists[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference / evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bow\n",
    "\n",
    "countvect_params = training_result['best_hyperparameters']['countvect_params']\n",
    "countvect_params['ngram_range'] = tuple(countvect_params['ngram_range'])     # convert list to tuple\n",
    "\n",
    "vectorizer = CountVectorizer(**countvect_params, max_features=2000)\n",
    "vectorizer.fit_transform(X_preprocessed)\n",
    "temp_vocabulary = set(vectorizer.get_feature_names_out())\n",
    "\n",
    "preprocessed_docs_tmp = [' '.join([w for w in doc.split() if w in temp_vocabulary])\n",
    "                    for doc in X_preprocessed]\n",
    "text_for_bow = preprocessed_docs_tmp\n",
    "\n",
    "tp = TopicModelDataPreparation()\n",
    "\n",
    "training_dataset = tp.fit(text_for_contextual=X, text_for_bow=text_for_bow, custom_embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75499, 2000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.X_bow.todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1180 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1180/1180 [00:02<00:00, 401.53it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_topic_distribution = best_model.get_doc_topic_distribution(training_dataset, n_samples=20)\n",
    "\n",
    "top_docs = best_model.get_top_documents_per_topic_id(X, doc_topic_distribution, 8, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEGIT THE BEST GAME EVER BETTER THAN MINECRAFT, SO MANY THINGS TO DO!!!!!!! BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!BEST GAME EVER!!!\n",
      "Just realized I've had this game for years and never reviewed it. Which is just horrible of me. Of all the games in my steam library this deserves a review. I've enjoyed this game a lot. I've also enjoyed reading the games development storie. The dev stopped development on this game years ago. Was 'encouraged' by his girlfriend to update it. That encouragement must have been awesome. He released not only one more major update for it, but nominated a team of developers to continue work on it for long after that. They are still updating it. Just this month (November of 2016) they released another update that in many games would have been a entire paid DLC but in this game is just par for the course of another free update. After this game was released it has seen many changes and updates. Adding content. Not nerfiing content, but adding more content. Even takign the time to fix bugs a long the way. They game is great. The amount of content I have gotten for free since I have bought this game is amazing though. Most AAA developers might have released a patch for it after release. Maybe a few pieces of paid DLC. The developers on this have released multiple patches a year for years after it was released. Most those patches equivalent to a paid DLC from a AAA title. Not sayign this is the only way to dev a game. Just saying it is a damn nice one to see. Thanks.\n",
      "Simply one of the best indie exploration-sandbox game of all time? I'm writing this review after the HUGE update that brought so much to the game than, after hundreds of hours already spent on this game, I still felt I was up for another nth playthrough, this time in goddam painful 'Expert mode' (but I'm enjoying it!) Seriously, which developer cherish more his baby than Terraria's one? The game is out since 2011, and yet 4 years after, you just happen to get a ton of new content for free for the thord time, for a game that has already been bought by so many people here. There is no profit involved here, just one man's dedication for his game and his community. If all developers could be as much Terraria is simply one of the best gaming experience I ever had. - It's retro stylish, without being ugly nor botched. - Musics are great and stick to the head as you could expect on old videogames. - There are a lot of things to do to really beat the game. - Exploring is both entertaining and rewarding. - Classic combat style and yet so much diversified thanks to a ton of different weapons. - I never felt like I was grinding for something. - You can build so much things, with so much - It's just totally amazing to watch all the crazy/beautiful things the community already made with this game. - Multiplayer is such a wonderful experience here, and it's even better since they made it easier to organize. What else could we ask for? I would buy this again.\n",
      "If these side scroller retro crafting type games appeal to you at all, this is one of the best. Absolutely recommended. Tons of content for the price. Probably the best game I've ever bought for this price! And they just keep adding more content!! Edit/update: Every time I scroll past this game in my Steam library, it makes me smile. I can't wait for a sequel/expansion/major update. What a game!\n",
      "Terraria is a truly amazing game experience, over the years countless updates have been added to the game enhancing it above and beyond what was already a great game. Terraria is a great game if you enjoy action adventure, with the potential to also build your hearts desire (in a 2D space). If you enjoy these kinds of games and have not played Terraria I highly recommend it. Great value for price and still to this day the developer over at Redigit have continued to put out countless updates adding new content for free.\n",
      "A super fun and addictive Sandbox Crafting 2D Side Scrolling Retro RPG. The amount of content and work put in to this little indie game is astounding. Literally as many hours or more of gameplay as The Witcher 3 right up until endgame, not to mention the insane replayability all thanks to the major free content updates the devs provide us every few months. One of the best price/content ratio games on steam right now, i got it for around $4-5 CND when it went on sale one time and it's one of the best choices i made on steam. Trust me, this game is well worth your hard earned money if you are a fan of the genre. Pick it up, you won't be disappointed.\n",
      "Terraria is currently the game I've invested the longest amount of time into. When I first booted up the game in one of its early versions, I was one of the players that easily classified Terraria as 'Minecraft, minus one Of course, back then I would not have imagined the plethora of free updates and content Terraria would become throughout its development cycle. Re-Logic, Terraria's developers, have given the gaming community one of the most content-rich, sandbox-exploration games. Even after they began other projects, Re-Logic continues to surprise Terraria communities with new content years after Terraria's release. At the time of writing this review, the game version of Terraria has reached If there was ever an announcement for yet another massive update in the form of I wouldn't be surprised, but excited to start from scratch to enjoy the new additions.\n",
      "Fantastic game, every time I play it the developer has added new stuff (all for free, not microtransactions). I'm completely amazed by the amount of support the developer has given this game. One of the best games I've ever played, it's a 2D sidescrolling open world adventure game. It has hours on hours of content for a fantastically low price \n",
      "I've played through this game multiple times with multiple groups of varying size. It's fun even when playing alone, but with a group of people this is pretty much the best game involving crafting that you can pick up. It has tons of content, the combat system is much better than most games of this type, it runs on pretty much anything, it's regularly on sale, the soundtrack is great, and it still gets gigantic free content updates years after release. I own it on Steamand DRM-free on GoG and the Humble Store and I've bought multiple copies for friends. over the years. If you've spent more than 10$ on computer games in your life and don't have this one in your library, you've made a mistake. The only reason not to get this game if you have the chance is if you really despise the genre or have nobody to play it with. The developers deserve praise perhaps more than any other developer for their continued free support and the many community suggestions they've implemented. TL;DR: This game is absolutely amazing, and well worth the asking price. If you don't pick it up full-price, get it on one of the many sales. A blast to play with a group of people.\n",
      "Much more than a 2D Minecraft, Terraria blends one of the deepest crafting systems of all time, a charming graphical style, Metroidvania elements and epic boss fights together into a game that's more than the sum of its parts. And best of all, the game's only continued to improve, greatly deepening in new features, graphics, weapons, bosses, and even adding entirely new ways to play the game, years after the original release. Almost anyone else would sell the content they give out for free as expansion packs. Not this team. Terraria continues to grow, with the update approaching. While much smaller in scope than the expansion pack-sized it shows the continued dedication that exists to improving an already incredible game. Must buy.\n"
     ]
    }
   ],
   "source": [
    "for tt in [t[0] for t in top_docs]:\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boss',\n",
       " 'buy',\n",
       " 'check',\n",
       " 'content',\n",
       " 'course',\n",
       " 'explore',\n",
       " 'felt',\n",
       " 'friend',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'get',\n",
       " 'great',\n",
       " 'hour',\n",
       " 'item',\n",
       " 'like',\n",
       " 'list',\n",
       " 'love',\n",
       " 'mention',\n",
       " 'minecraft',\n",
       " 'new',\n",
       " 'number',\n",
       " 'one',\n",
       " 'play',\n",
       " 'recommend',\n",
       " 'say',\n",
       " 'special',\n",
       " 'spoil',\n",
       " 'still',\n",
       " 'stuff',\n",
       " 'terrarium',\n",
       " 'time',\n",
       " 'update',\n",
       " 'well',\n",
       " 'world']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# within the topic lists (the words)\n",
    "# find out common words between topics\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "topic_list = best_model.get_topic_lists(k=10)\n",
    "\n",
    "common_words = set()\n",
    "for topic1, topic2 in combinations(topic_list, 2):\n",
    "    common_words.update(set(topic1).intersection(set(topic2)))\n",
    "\n",
    "common_words = list(common_words)\n",
    "common_words.sort()\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-test-tm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
