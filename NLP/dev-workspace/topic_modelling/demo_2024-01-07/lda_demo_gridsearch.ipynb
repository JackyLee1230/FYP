{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo ipynb for LDA\n",
    "\n",
    "Creating training pipeline on different situations (15/01/2024)\n",
    "\n",
    "- For all games (using 0.1 and 0.5 of the whole dataset for pipeline developments)\n",
    "- For top 11 genres\n",
    "\n",
    "- (if possible): per game, focus on large and small (indie) games\n",
    "\n",
    "Do the same thing for all three model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import gensim\n",
    "\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "\n",
    "import pyLDAvis\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download nltk stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# download spacy stopwords\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training conditions\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class TRAINING_CONDS(Enum):\n",
    "    ALL_GAMES = 1\n",
    "    ALL_GAMES_LARGE = 2\n",
    "    BY_GENRE = 3\n",
    "    ALL_GAMES_TINY = 4\n",
    "\n",
    "# training condition\n",
    "training_cond = TRAINING_CONDS.ALL_GAMES_TINY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 41801 entries, 2265566 to 1363240\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   index         41801 non-null  int64 \n",
      " 1   app_id        41801 non-null  int64 \n",
      " 2   app_name      41801 non-null  object\n",
      " 3   review_text   41801 non-null  object\n",
      " 4   review_score  41801 non-null  int64 \n",
      " 5   review_votes  41801 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# load a dataset\n",
    "\n",
    "GENRES = ['Action', 'Indie', 'Adventure', 'RPG', 'Strategy', 'Simulation', 'Free to Play', 'Causal', 'Massively Multiplayer', 'Racing', 'Sports']\n",
    "\n",
    "training_genre_id = 2\n",
    "\n",
    "if training_cond == TRAINING_CONDS.ALL_GAMES:\n",
    "    dataset_path = Path('../dataset_cleaned_heartless_sampled_for_demo.pkl')\n",
    "elif training_cond == TRAINING_CONDS.ALL_GAMES_LARGE:\n",
    "    dataset_path = Path('../dataset_cleaned_heartless_sampled_for_demo_large.pkl')\n",
    "elif training_cond == TRAINING_CONDS.ALL_GAMES_TINY:\n",
    "    dataset_path = Path('../dataset_cleaned_heartless_sampled_for_demo_tiny.pkl')\n",
    "elif training_cond == TRAINING_CONDS.BY_GENRE:\n",
    "    dataset_path = Path(f'../../dataset/topic_modelling/top_11_genres/{training_genre_id:02}_{GENRES[training_genre_id]}.pkl')\n",
    "\n",
    "# dataset_path = Path('../../dataset/topic_modelling/top_10_games/00_Terraria.pkl')\n",
    "\n",
    "# dataset_path = Path('../dataset_cleaned_heartless_sampled_for_demo.pkl')\n",
    "\n",
    "\n",
    "dataset = pd.read_pickle(dataset_path)\n",
    "\n",
    "dataset.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../sa')\n",
    "\n",
    "%autoreload 2\n",
    "import str_cleaning_functions\n",
    "\n",
    "def cleaning(df, review):\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_links(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_links2(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.clean(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.deEmojify(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_non_letters(x))\n",
    "    df[review] = df[review].apply(lambda x: x.lower())\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.unify_whitespaces(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.remove_stopword(x))\n",
    "    df[review] = df[review].apply(lambda x: str_cleaning_functions.unify_whitespaces(x))\n",
    "\n",
    "def cleaning_strlist(str_list):\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.remove_links(x), str_list))\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.remove_links2(x), str_list))\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.clean(x), str_list))\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.deEmojify(x), str_list))\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.remove_non_letters(x), str_list))\n",
    "    str_list = list(map(lambda x: x.lower(), str_list))\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.unify_whitespaces(x), str_list))\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.remove_stopword(x), str_list))\n",
    "    str_list = list(map(lambda x: str_cleaning_functions.unify_whitespaces(x), str_list))\n",
    "    return str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply data preprocessing\n",
    "\n",
    "cleaning(dataset, 'review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['review_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actually already wrote huge review short great game rage inducing play play minutes time hopelessly frustrating said funny fun',\n",
       "       'far thrilling game ever played fan soccer soccer games one ever play awesome game play highly recommend game anyone age even infants jks',\n",
       "       'might opinon find game boring uninteresting hard get controlls really weird graphics decent tho yet play assasins creed games besides one yeah',\n",
       "       ...,\n",
       "       'funny game alot geek culture built swearing side thoroughly enjoyed every part although think classic school adventure clickers easy time navigating game rusty get sale think enjoy',\n",
       "       'ftl faster light perhaps one greatest games time ever',\n",
       "       'okay saw game expected high quality remake like bionic commando rearmed duck tales remastered know great classic games uplifted polished graphics sound honestly whole point get dose retro nostalgia care might well download rom image play old version emulator free right long time assumed strider would like oh wow wrong much better game nostalgia made genuine love old platformer games strives bring something fresh exciting genre like kids back thought future videogames would like supercharged progression already come true also convinced best metroidvania since super metroid never thought say'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# t = nltk.word_tokenize(X[0])\n",
    "# tt = nltk.pos_tag(t)\n",
    "# tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do lemmatization, but not stemming (as part of speech is important in topic modelling)\n",
    "# use nltk wordnet for lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# from https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word\n",
    "\n",
    "# from: https://www.cnblogs.com/jclian91/p/9898511.html\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None     # if none -> created as noun by wordnet\n",
    "    \n",
    "def lemmatization(text):\n",
    "   # use nltk to get PoS tag\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "\n",
    "    # then we only need adj, adv, verb, noun\n",
    "    # convert from nltk Penn Treebank tag to wordnet tag\n",
    "    wn_tagged = list(map(lambda x: (x[0], get_wordnet_pos(x[1])), tagged))\n",
    "\n",
    "    # lemmatize by the PoS\n",
    "    lemmatized = list(map(lambda x: lemma.lemmatize(x[0], pos=x[1] if x[1] else wordnet.NOUN), wn_tagged))\n",
    "    # lemma.lemmatize(wn_tagged[0], pos=wordnet.NOUN)\n",
    "\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize the data\n",
    "\n",
    "X_lemmatized = list(map(lambda x: lemmatization(x), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'already',\n",
       " 'write',\n",
       " 'huge',\n",
       " 'review',\n",
       " 'short',\n",
       " 'great',\n",
       " 'game',\n",
       " 'rage',\n",
       " 'induce',\n",
       " 'play',\n",
       " 'play',\n",
       " 'minute',\n",
       " 'time',\n",
       " 'hopelessly',\n",
       " 'frustrate',\n",
       " 'say',\n",
       " 'funny',\n",
       " 'fun']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lematized data, as separate pickle file\n",
    "\n",
    "X_lemmatized_file = dataset_path.parent.joinpath('cleaned_lemmatized', dataset_path.stem + '_cleaned_lemmatized.pkl')\n",
    "\n",
    "if not X_lemmatized_file.parent.exists():\n",
    "    X_lemmatized_file.parent.mkdir()\n",
    "\n",
    "with open(X_lemmatized_file, \"wb\") as f:\n",
    "    pickle.dump(X_lemmatized, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the lematized data, as separate pickle file\n",
    "# for convenient hyperparameter selection\n",
    "\n",
    "# X_lemmatized_file = dataset_path.parent.joinpath('cleaned_lemmatized', dataset_path.stem + '_cleaned_lemmatized.pkl')\n",
    "\n",
    "# with open(X_lemmatized_file, \"rb\") as f:\n",
    "#     X_lemmatized = pickle.load(f)\n",
    "\n",
    "# X_lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gensim to build a dictionary and train our LDAModel\n",
    "\n",
    "id2word = gensim.corpora.Dictionary(X_lemmatized)\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in X_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a grid search for hyperparameter selection\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "#     \"\"\"\n",
    "#     Compute c_v coherence for various number of topics\n",
    "\n",
    "#     Parameters:\n",
    "#     ----------\n",
    "#     dictionary : Gensim dictionary\n",
    "#     corpus : Gensim corpus\n",
    "#     texts : List of input texts\n",
    "#     limit : Max num of topics\n",
    "\n",
    "#     Returns:\n",
    "#     -------\n",
    "#     model_list : List of LDA topic models\n",
    "#     coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "\n",
    "#     From: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "#     \"\"\"\n",
    "#     coherence_values = []\n",
    "#     model_list = []\n",
    "#     for num_topics in range(start, limit, step):\n",
    "#         print(f'num_topics: {num_topics}')\n",
    "#         model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                                 id2word=id2word,\n",
    "#                                                 num_topics=num_topics, \n",
    "#                                                 random_state=100,\n",
    "#                                                 update_every=1,\n",
    "#                                                 chunksize=100,\n",
    "#                                                 passes=10,\n",
    "#                                                 alpha='auto',\n",
    "#                                                 per_word_topics=True)\n",
    "#         model_list.append(model)\n",
    "#         coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "#         print(f'coherence: {coherencemodel.get_coherence()}')\n",
    "#         coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "#     return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search folder: lda_multicore_grid_search_20240118_001906\n",
      "Created config.json at: lda_multicore_grid_search_20240118_001906/config.json\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.7, 'offset': 16}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.13285839262271096\n",
      "{'best_metric': -0.13285839262271096, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.7_offset_16', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.7, 'offset': 64}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.10699026017939921\n",
      "{'best_metric': -0.10699026017939921, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.7_offset_64', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.7, 'offset': 128}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.05897959629995499\n",
      "{'best_metric': -0.05897959629995499, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.7_offset_128', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.8, 'offset': 16}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.10494476314719622\n",
      "{'best_metric': -0.05897959629995499, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.7_offset_128', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.8, 'offset': 64}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.04458478136896265\n",
      "{'best_metric': -0.04458478136896265, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.8_offset_64', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.8, 'offset': 128}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.021729748712587933\n",
      "{'best_metric': -0.021729748712587933, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.8_offset_128', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.9, 'offset': 16}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.054033851637396824\n",
      "{'best_metric': -0.021729748712587933, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.8_offset_128', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.9, 'offset': 64}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.029946066949048118\n",
      "{'best_metric': -0.021729748712587933, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.8_offset_128', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 10, 'decay': 0.9, 'offset': 128}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.007280844935916809\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.7, 'offset': 16}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.18408057615094958\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.7, 'offset': 64}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.09628239192542186\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.7, 'offset': 128}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.06407030823892387\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.06407030823892387, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.8, 'offset': 16}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.1491834123574599\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.06407030823892387, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.1491834123574599, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.8, 'offset': 64}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.053598904166278105\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.06407030823892387, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.1491834123574599, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.053598904166278105, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.8, 'offset': 128}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.0301156316257134\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.06407030823892387, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.1491834123574599, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.053598904166278105, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.0301156316257134, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.9, 'offset': 16}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.061627229997780995\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.06407030823892387, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.1491834123574599, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.053598904166278105, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.0301156316257134, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.061627229997780995, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.9, 'offset': 64}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.031249063694558155\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.06407030823892387, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.1491834123574599, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.053598904166278105, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.0301156316257134, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.061627229997780995, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.031249063694558155, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 20, 'decay': 0.9, 'offset': 128}\n",
      "Computing evaluation metric\n",
      "Evaluation metric (c_npmi): -0.0174799628428725\n",
      "{'best_metric': -0.007280844935916809, 'best_model_checkpoint': 'lda_multicore_grid_search_20240118_001906/lda_multicore_num_topics_10_decay_0.9_offset_128', 'best_hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}, 'metric_type': 'c_npmi', 'log_history': [{'metric': -0.13285839262271096, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10699026017939921, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.05897959629995499, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.10494476314719622, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.04458478136896265, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.021729748712587933, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.054033851637396824, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.029946066949048118, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.007280844935916809, 'hyperparameters': {'num_topics': 10, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.18408057615094958, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.09628239192542186, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.06407030823892387, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.7, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.1491834123574599, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.053598904166278105, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.0301156316257134, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.8, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.061627229997780995, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 16, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.031249063694558155, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 64, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}, {'metric': -0.0174799628428725, 'hyperparameters': {'num_topics': 20, 'workers': 3, 'chunksize': 2000, 'passes': 10, 'alpha': 'symmetric', 'eta': None, 'decay': 0.9, 'offset': 128, 'eval_every': 10, 'iterations': 50, 'gamma_threshold': 0.001, 'minimum_probability': 0.01, 'random_state': 42, 'minimum_phi_value': 0.01, 'per_word_topics': False, 'dtype': \"<class 'numpy.float32'>\"}}]}\n",
      "Saved result.json at: lda_multicore_grid_search_20240118_001906/result.json\n",
      "\n",
      "\n",
      "\n",
      "Training with current search space: {'num_topics': 30, 'decay': 0.7, 'offset': 16}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFull\u001b[0m                                      Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/gensim/models/ldamulticore.py:298\u001b[0m, in \u001b[0;36mLdaMulticore.update\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[43mjob_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     queue_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/multiprocessing/queues.py:90\u001b[0m, in \u001b[0;36mQueue.put\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Full\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_notempty:\n",
      "\u001b[0;31mFull\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 222\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrid Search ends\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, best_model_path, best_hyperparameters\n\u001b[0;32m--> 222\u001b[0m best_model, best_model_path, best_hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_lemmatized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlda_multicore_grid_search_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 144\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(X, hyperparameters, search_space, save_folder, save_each_models)\u001b[0m\n\u001b[1;32m    141\u001b[0m hyperparameters\u001b[38;5;241m.\u001b[39mupdate(search_space_dict)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mldamulticore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaMulticore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Evaluation starts\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing evaluation metric\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/gensim/models/ldamulticore.py:186\u001b[0m, in \u001b[0;36mLdaMulticore.__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(alpha, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m alpha \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLdaMulticore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminimum_probability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminimum_phi_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminimum_phi_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_word_topics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/gensim/models/ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/gensim/models/ldamulticore.py:309\u001b[0m, in \u001b[0;36mLdaMulticore.update\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mFull:\n\u001b[1;32m    307\u001b[0m             \u001b[38;5;66;03m# in case the input job queue is full, keep clearing the\u001b[39;00m\n\u001b[1;32m    308\u001b[0m             \u001b[38;5;66;03m# result queue, to make sure we don't deadlock\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m             \u001b[43mprocess_result_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     process_result_queue()\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# endfor single corpus pass\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# wait for all outstanding jobs to finish\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/site-packages/gensim/models/ldamulticore.py:275\u001b[0m, in \u001b[0;36mLdaMulticore.update.<locals>.process_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    273\u001b[0m merged_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_queue\u001b[38;5;241m.\u001b[39mempty():\n\u001b[0;32m--> 275\u001b[0m     other\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mresult_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    276\u001b[0m     queue_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    277\u001b[0m     merged_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/multiprocessing/connection.py:421\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxsize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;241m>\u001b[39m maxsize:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fyp-test-wsl-tm/lib/python3.9/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def _init_LdaMulticore_params(corpus=None, num_topics=100, id2word=None, workers=None, chunksize=2000, \n",
    "        passes=1, batch=False, alpha='symmetric', eta=None, decay=0.5, offset=1.0, \n",
    "        eval_every=10, iterations=50, gamma_threshold=0.001, random_state=None, \n",
    "        minimum_probability=0.01, minimum_phi_value=0.01, per_word_topics=False, dtype=np.float32):\n",
    "    \n",
    "    hyperparameters = dict()\n",
    "    hyperparameters['corpus'] = corpus\n",
    "    hyperparameters[\"num_topics\"] = num_topics\n",
    "    hyperparameters['id2word'] = id2word\n",
    "    hyperparameters[\"workers\"] = workers\n",
    "    hyperparameters[\"chunksize\"] = chunksize\n",
    "    hyperparameters[\"passes\"] = passes\n",
    "    hyperparameters[\"alpha\"] = alpha\n",
    "    hyperparameters[\"eta\"] = eta\n",
    "    hyperparameters[\"decay\"] = decay\n",
    "    hyperparameters[\"offset\"] = offset\n",
    "    hyperparameters[\"eval_every\"] = eval_every\n",
    "    hyperparameters[\"iterations\"] = iterations\n",
    "    hyperparameters[\"gamma_threshold\"] = gamma_threshold\n",
    "    hyperparameters['minimum_probability'] = minimum_probability\n",
    "    hyperparameters[\"random_state\"] = random_state\n",
    "    hyperparameters['minimum_phi_value'] = minimum_phi_value\n",
    "    hyperparameters['per_word_topics'] = per_word_topics\n",
    "    hyperparameters['dtype'] = dtype\n",
    "\n",
    "    if \"alpha\" in hyperparameters:\n",
    "        if isinstance(hyperparameters[\"alpha\"], float):\n",
    "            hyperparameters[\"alpha\"] = [\n",
    "                hyperparameters[\"alpha\"]\n",
    "            ] * hyperparameters[\"num_topics\"]\n",
    "\n",
    "    return hyperparameters\n",
    "\n",
    "def _init_config_dict(model_name:str, hyperparameters:dict, search_space_dict:dict):\n",
    "    # init dict for config.json\n",
    "\n",
    "    config = {}\n",
    "    config['model'] = model_name\n",
    "    config.update(hyperparameters)\n",
    "\n",
    "    config.pop('corpus', '')\n",
    "    config.pop('id2word', '')\n",
    "    \n",
    "    # remove hyperparameters that are in the search space\n",
    "    for key in search_space_dict.keys():\n",
    "        config.pop(key, '')\n",
    "\n",
    "    config['dtype'] = str(config['dtype'])\n",
    "\n",
    "    # store the search space\n",
    "    config['search_space'] = search_space_dict\n",
    "\n",
    "    config['gensim_version'] = str(gensim.__version__)\n",
    "\n",
    "    return config\n",
    "\n",
    "def _init_result_dict():\n",
    "    # init dict for result.json\n",
    "\n",
    "    result = {}\n",
    "    result['best_metric'] = -float('inf')\n",
    "    result['best_model_checkpoint'] = \"\"\n",
    "    result['best_hyperparameters'] = dict()\n",
    "    result[\"metric_type\"] = \"\"\n",
    "    result[\"log_history\"] = list()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "hyperparameters = _init_LdaMulticore_params(\n",
    "    corpus=corpus, num_topics=100, id2word=id2word, \n",
    "    workers=3, chunksize=2000, random_state=42, passes=10)\n",
    "\n",
    "# create search_space dict\n",
    "search_space = dict()\n",
    "\n",
    "search_space['num_topics'] = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "search_space['decay'] = [0.7, 0.8, 0.9]\n",
    "search_space['offset'] = [16, 64, 128]\n",
    "\n",
    "from itertools import product\n",
    "import json\n",
    "from gensim.models import CoherenceModel\n",
    "from copy import deepcopy\n",
    "\n",
    "def grid_search(X, hyperparameters:dict, search_space:dict, save_folder:Path, save_each_models=True):\n",
    "    \"\"\"\n",
    "    Perform grid search for LDA model hyperparameter selection\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : List of input texts\n",
    "    hyperparameters : dict of hyperparameters\n",
    "    search_space : dict of search space for hyperparameters\n",
    "    save_each_models : save each model or not\n",
    "    save_path : path to save the model\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    best_model : best model\n",
    "    best_model_path : path to the best model\n",
    "    best_hyperparameters : best hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "    if not save_folder.exists():\n",
    "        save_folder.mkdir()\n",
    "\n",
    "    print(f'Grid Search folder: {save_folder}')\n",
    "\n",
    "    # TODO: load the josn files to contiunue the search\n",
    "\n",
    "    # init some json files for saving the results\n",
    "    config = _init_config_dict('lda_multicore', hyperparameters, search_space)\n",
    "    # save config\n",
    "    with open(save_folder.joinpath('config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "    print('Created config.json at:', save_folder.joinpath('config.json'))\n",
    "\n",
    "    result = _init_result_dict()\n",
    "    coherence_str = 'c_npmi'\n",
    "    result['metric_type'] = coherence_str\n",
    "\n",
    "    # init\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    best_metric_score = -float('inf')\n",
    "\n",
    "    # get the search space keys\n",
    "    keys = list(search_space.keys())\n",
    "\n",
    "    # iterate through the search space by using combination func\n",
    "    for values in product(*search_space.values()):\n",
    "\n",
    "        # create a dict of search space hyperparams\n",
    "        search_space_dict = dict(zip(keys, values))\n",
    "\n",
    "        print(f'Training with current search space: {search_space_dict}')\n",
    "\n",
    "        # update existing hyperparams dict\n",
    "        hyperparameters.update(search_space_dict)\n",
    "\n",
    "        # train the model\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(**hyperparameters)\n",
    "\n",
    "        ##########\n",
    "        # Evaluation starts\n",
    "        ##########\n",
    "\n",
    "        print('Computing evaluation metric')\n",
    "\n",
    "        # modify the evaluation part to include any evaluations you want\n",
    "\n",
    "\n",
    "        # compute the coherence\n",
    "        coherencemodel = CoherenceModel(model=model, texts=X, dictionary=id2word, coherence=coherence_str)\n",
    "        metric_score = coherencemodel.get_coherence()\n",
    "\n",
    "        print(f'Evaluation metric ({coherence_str}): {metric_score}')\n",
    "\n",
    "        ##########\n",
    "        # Evaluation ends\n",
    "        ##########\n",
    "\n",
    "        ##########\n",
    "        # Save models\n",
    "        ##########\n",
    "\n",
    "        # create the folder by using search_space keys and current hyperparams values\n",
    "        model_path = save_folder.joinpath(\n",
    "            'lda_multicore_' + '_'.join([f'{key}_{value}' for key, value in search_space_dict.items()])\n",
    "        )\n",
    "\n",
    "        if not model_path.exists():\n",
    "            model_path.mkdir(parents=True)\n",
    "\n",
    "        # save the model\n",
    "        if save_each_models:\n",
    "            model.save(str(model_path.joinpath('lda_multicore')))\n",
    "\n",
    "        ##########\n",
    "        # Save models ends\n",
    "        ##########\n",
    "            \n",
    "        model_hyperparameters = deepcopy(hyperparameters)\n",
    "        model_hyperparameters.pop('corpus', '')\n",
    "        model_hyperparameters.pop('id2word', '')\n",
    "        model_hyperparameters['dtype'] = str(model_hyperparameters['dtype'])\n",
    "            \n",
    "        if metric_score > best_metric_score:\n",
    "            best_metric_score = metric_score\n",
    "            best_model = model\n",
    "            best_model_path = model_path\n",
    "            best_hyperparameters = model_hyperparameters\n",
    "            \n",
    "        ###########\n",
    "        # Update result dict and json file\n",
    "        ###########\n",
    "\n",
    "        model_log_history = dict()\n",
    "        model_log_history['metric'] = metric_score\n",
    "        model_log_history['hyperparameters'] = model_hyperparameters\n",
    "\n",
    "        result['best_metric'] = best_metric_score\n",
    "        result['best_model_checkpoint'] = str(best_model_path)      # relative path\n",
    "        result['best_hyperparameters'] = model_hyperparameters\n",
    "        result[\"log_history\"].append(model_log_history)\n",
    "\n",
    "        print(result)\n",
    "\n",
    "        # save result\n",
    "        with open(save_folder.joinpath('result.json'), 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "\n",
    "        print(\"Saved result.json at:\", save_folder.joinpath('result.json'))\n",
    "        print('\\n\\n')\n",
    "\n",
    "    print('Grid Search ends')\n",
    "    return best_model, best_model_path, best_hyperparameters\n",
    "\n",
    "\n",
    "best_model, best_model_path, best_hyperparameters = grid_search(\n",
    "    X_lemmatized, hyperparameters, search_space, \n",
    "    Path(f'lda_multicore_grid_search_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = 20\n",
    "\n",
    "# Online LDA, how to effective train LDA models\n",
    "# https://papers.nips.cc/paper_files/paper/2010/hash/71f6278d140af599e06ad9bf1ba03cb0-Abstract.html\n",
    "\n",
    "lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                             id2word=id2word,\n",
    "                                             num_topics=N_TOPICS,         # later can use grid search to find the best number of topics\n",
    "                                             random_state=42,\n",
    "                                             chunksize=2048,                # chunk size affects memory consumption, and updating speed (like DL batch_size). https://groups.google.com/g/gensim/c/FE7_FYSconA\n",
    "                                             passes=10,                     # no. of passes over the whole corpus. If larger chunksize, then the passes should be larger too.\n",
    "                                            #  alpha='auto',\n",
    "                                             workers=3)     # workers = no. of cores (physical cores, but not logical threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=10)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model\n",
    "\n",
    "we need to save the corpora.Dictionary and the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the LDA multicore model (and the corpora.Dictionary object) automatically\n",
    "\n",
    "lda_save_folder = Path(f'lda_model_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "if not lda_save_folder.exists():\n",
    "    lda_save_folder.mkdir()\n",
    "\n",
    "lda_model.save(str(lda_save_folder.joinpath('lda_model')))     # no need to add file extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "\n",
    "gensim provide functions to calculate, so we don't need to install octis (as the evaluation backend of octis also relies on gensim)\n",
    "\n",
    "octis seems awesome for simple development, but it installs many packages ;("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = lemmatized words (?) (list of list of str)\n",
    "\n",
    "# create a result object from the LDAMulticore model for octis evaluation\n",
    "# referencing from https://github.com/MIND-Lab/OCTIS/blob/master/octis/models/LDA.py\n",
    "# and guideline in README: https://github.com/MIND-Lab/OCTIS/tree/master\n",
    "result_lda_online = {}\n",
    "result_lda_online['topic-word-matrix'] = lda_model.get_topics()\n",
    "\n",
    "top_words = 10\n",
    "topics_output = []\n",
    "for topic in result_lda_online[\"topic-word-matrix\"]:\n",
    "    top_k = np.argsort(topic)[-top_words:]\n",
    "    top_k_words = list(reversed([id2word[i] for i in top_k]))\n",
    "    topics_output.append(top_k_words)\n",
    "result_lda_online[\"topics\"] = topics_output\n",
    "\n",
    "def _get_topic_document_matrix(lda_model, corpus, num_topics=10):\n",
    "    \"\"\"\n",
    "    Return the topic representation of the\n",
    "    corpus\n",
    "    \"\"\"\n",
    "\n",
    "    id_corpus = corpus\n",
    "\n",
    "    doc_topic_tuples = []\n",
    "    for document in id_corpus:\n",
    "        doc_topic_tuples.append(\n",
    "            lda_model.get_document_topics(document, minimum_probability=0))\n",
    "\n",
    "    topic_document = np.zeros((num_topics, len(doc_topic_tuples)))\n",
    "\n",
    "    for ndoc in range(len(doc_topic_tuples)):\n",
    "        document = doc_topic_tuples[ndoc]\n",
    "        for topic_tuple in document:\n",
    "            topic_document[topic_tuple[0]][ndoc] = topic_tuple[1]\n",
    "    return topic_document\n",
    "\n",
    "result_lda_online['topic-document-matrix'] = _get_topic_document_matrix(lda_model, corpus, num_topics=N_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_topics(num_topics=N_TOPICS, num_words=10, formatted=True, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup: get the model's topics in their native ordering...\n",
    "all_topics = lda_model.print_topics()\n",
    "# ...then create a empty list per topic to collect the docs:\n",
    "docs_per_topic = [[] for _ in all_topics]\n",
    "\n",
    "# now, for every doc...\n",
    "for doc_id, doc_bow in enumerate(corpus):\n",
    "    # ...get its topics...\n",
    "    doc_topics = lda_model.get_document_topics(doc_bow)\n",
    "    # ...& for each of its topics...\n",
    "    for topic_id, score in doc_topics:\n",
    "        # ...add the doc_id & its score to the topic's doc list\n",
    "        docs_per_topic[topic_id].append((doc_id, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're interested in the top docs per topic, you can further sort each list's pairs by their score\n",
    "\n",
    "for doc_list in docs_per_topic:\n",
    "    doc_list.sort(key=lambda id_and_score: id_and_score[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs_per_topic[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top 10 documents for each topic, also the name of the game\n",
    "for topic_id, docs in enumerate(docs_per_topic):\n",
    "    print(f'Topic {topic_id + 1}:')\n",
    "    for doc_id, score in docs[:10]:\n",
    "        print(f'Game: {dataset.iloc[doc_id][\"app_name\"]}')\n",
    "        print(f'Doc ID: {doc_id}')\n",
    "        print(f'Score: {score}')\n",
    "        print(f'Doc: {dataset.iloc[doc_id][\"review_text\"]}')\n",
    "        print()\n",
    "    print('\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[1655473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1655473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lda_online['topic-document-matrix'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.get_topics().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(result_lda_online['topic-document-matrix'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "\n",
    "instead of using octis, we use gensim provided CoherenceModel object,  \n",
    "as octis also uses this module for calculating the coherence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=X_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_cv = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using c_npmi\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=X_lemmatized, dictionary=id2word, coherence='c_npmi')\n",
    "coherence_npmi = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_npmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference test\n",
    "\n",
    "inference_test = [\"well its been fun guys, but that's it, no more updates, that one was the last one, there is no longer going to be anymore content for this game anymore, there is no way to replay it as there won't be any updates, nope, that was it, the last update, nothing more, this game has no new ways to experience it as there is no more content updates, nothing new to freshen up the experience, its such a shame that this game has no replay-ability, once you beat the game there is like no point to playing again, as they said guys 1.2 will be they final update. nothing more after 1.2, there is no chance they will make another final update right? several years and final updates later: alright, thats it, no more updates we wont be getting anymore, thats it, nothing more, no more updates, for real this time... oh god, redigit made another tweet.\",\n",
    "                  \"keeps forcing me to play it\",\n",
    "'''I will leave the cat here, so that everybody who passes by can pet it and give it a thumbs up and awards\n",
    "　　　 　　／＞　　フ\n",
    "　　　 　　| 　_　 _ l\n",
    "　 　　 　／` ミ＿xノ\n",
    "　　 　 /　　　 　 |\n",
    "　　　 /　 ヽ　　 ﾉ\n",
    "　 　 │　　|　|　|\n",
    "　／￣|　　 |　|　|\n",
    "　| (￣ヽ＿_ヽ_)__)\n",
    "　＼二つ''']\n",
    "\n",
    "inference_test = cleaning_strlist(inference_test)\n",
    "\n",
    "inference_test = list(map(lambda x: lemmatization(x), inference_test))\n",
    "\n",
    "corpus_test = [id2word.doc2bow(text) for text in inference_test]\n",
    "\n",
    "test_output = lda_model[corpus_test]\n",
    "\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inference\n",
    "\n",
    "corpus_test = [id2word.doc2bow(text) for text in inference_test]\n",
    "\n",
    "output_test = lda_model[corpus_test]\n",
    "\n",
    "for i in range(len(output_test)):\n",
    "    # print(sorted(test_output[i], key=lambda x: x[1], reverse=True))\n",
    "    print(sorted(output_test[i], key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model (both corpora Dictionary and the LDA model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del id2word\n",
    "del lda_model\n",
    "\n",
    "model_datetime = datetime(2024, 1, 15, 0, 21, 57)\n",
    "lda_save_folder = Path(f'lda_model_{model_datetime.strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "\n",
    "# id2word_load = gensim.corpora.Dictionary.load('lda_model.id2word')\n",
    "id2word_l = gensim.corpora.Dictionary.load(str(lda_save_folder.joinpath('lda_model.id2word')))\n",
    "\n",
    "lda_model_l = gensim.models.ldamulticore.LdaMulticore.load(str(lda_save_folder.joinpath('lda_model')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test2 = [id2word_l.doc2bow(text) for text in inference_test]\n",
    "\n",
    "output_test2 = lda_model_l[corpus_test2]\n",
    "\n",
    "for i in range(len(output_test2)):\n",
    "    print(sorted(output_test2[i], key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-test-tm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
